{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AF - Agentic Flow Framework","text":"<p>Call-Spec Discipline for LLM Agent Workflows</p>"},{"location":"#see-the-difference","title":"See the Difference","text":"<p>Writing multi-agent flows with the Pure SDK requires significant boilerplate. The agentic flow pattern eliminates it.</p> Pure SDK + ChatKit \u2014 ~126 lines of ceremony  <pre><code>\"\"\"Pure Agents SDK - Complex multi-agent with ChatKit streaming.\"\"\"\n\nimport asyncio\nfrom typing import Any\n\nfrom agents import Agent, ModelSettings, Runner\nfrom agents.extensions.chatkit import (\n    AgentContext,\n    close_workflow,\n    emit_phase_label,\n    stream_agent_response,\n)\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import StreamingResponse\nfrom openai.types.shared.reasoning import Reasoning\n\napp = FastAPI()\n\n\ndef create_agent(name: str, instructions: str) -&gt; Agent:\n    return Agent(\n        name=name,\n        instructions=instructions,\n        model=\"gpt-5.2\",\n        model_settings=ModelSettings(\n            store=True,\n            reasoning=Reasoning(effort=\"medium\", summary=\"auto\"),\n        ),\n    )\n\n\nclassifier = create_agent(\"classifier\", \"Classify as SIMPLE or COMPLEX.\")\nresearcher = create_agent(\"researcher\", \"Research the topic.\")\nreviewer = create_agent(\"reviewer\", \"Review. Reply APPROVED or REJECTED.\")\nrefiner = create_agent(\"refiner\", \"Refine based on feedback.\")\nresponder = create_agent(\"responder\", \"Give final response.\")\n\n\ndef to_messages(text: str) -&gt; list[dict[str, Any]]:\n    return [{\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": text}]}]\n\n\n@app.post(\"/chatkit\")\nasync def chatkit_endpoint(request: Request):\n    body = await request.json()\n    messages = body.get(\"messages\", [])\n    user_input = messages[-1][\"content\"][0][\"text\"]\n\n    agent_context = AgentContext()\n    event_queue: asyncio.Queue = asyncio.Queue()\n\n    async def flow_logic():\n        try:\n            # Phase 1: Classification\n            emit_phase_label(agent_context, \"Classification\")\n            result = Runner.run_streamed(classifier, to_messages(user_input), context=agent_context)\n            async for event in stream_agent_response(agent_context, result):\n                await event_queue.put(event)\n            classification = result.final_output\n            await close_workflow(agent_context)\n\n            # Phase 2: Research (conditional)\n            if \"COMPLEX\" in classification.upper():\n                emit_phase_label(agent_context, \"Research\")\n                result = Runner.run_streamed(\n                    researcher, to_messages(user_input), context=agent_context\n                )\n                async for event in stream_agent_response(agent_context, result):\n                    await event_queue.put(event)\n                draft = result.final_output\n                await close_workflow(agent_context)\n            else:\n                draft = user_input\n\n            # Phase 3: Review loop\n            for attempt in range(3):\n                emit_phase_label(agent_context, f\"Review (attempt {attempt + 1})\")\n                result = Runner.run_streamed(\n                    reviewer, to_messages(f\"Review:\\n{draft}\"), context=agent_context\n                )\n                async for event in stream_agent_response(agent_context, result):\n                    await event_queue.put(event)\n                review = result.final_output\n                await close_workflow(agent_context)\n\n                if \"APPROVED\" in review.upper():\n                    break\n\n                emit_phase_label(agent_context, f\"Refinement (attempt {attempt + 1})\")\n                result = Runner.run_streamed(\n                    refiner,\n                    to_messages(f\"Draft:\\n{draft}\\n\\nFeedback:\\n{review}\"),\n                    context=agent_context,\n                )\n                async for event in stream_agent_response(agent_context, result):\n                    await event_queue.put(event)\n                draft = result.final_output\n                await close_workflow(agent_context)\n\n            # Phase 4: Final response\n            emit_phase_label(agent_context, \"Final Response\")\n            result = Runner.run_streamed(\n                responder, to_messages(f\"Based on:\\n{draft}\"), context=agent_context\n            )\n            async for event in stream_agent_response(agent_context, result):\n                await event_queue.put(event)\n            await close_workflow(agent_context)\n\n        except Exception:\n            try:\n                await close_workflow(agent_context)\n            except Exception:\n                pass\n            raise\n        finally:\n            await event_queue.put(None)\n\n    async def event_generator():\n        asyncio.create_task(flow_logic())\n        while True:\n            event = await event_queue.get()\n            if event is None:\n                break\n            yield f\"data: {event.model_dump_json()}\\n\\n\"\n\n    return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n</code></pre> <p>Problems:</p> <ul> <li> Manual <code>emit_phase_label()</code> + <code>close_workflow()</code> for every phase</li> <li> <code>async for event in stream_agent_response()</code> repeated everywhere</li> <li> <code>try/finally</code> blocks to ensure <code>close_workflow()</code> on errors</li> <li> Event queue management boilerplate</li> <li> Business logic buried in infrastructure code</li> </ul> <p>The same workflow using the agentic flow approach:</p> Flow \u2014 43 lines ChatKit Server \u2014 20 linesCLI \u2014 16 lines <pre><code>\"\"\"Agentic Flow - Same complex flow, clean code.\"\"\"\n\nimport agentic_flow as af\n\nclassifier = af.Agent(\n    name=\"classifier\",\n    instructions=\"Classify as SIMPLE or COMPLEX.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\nresearcher = af.Agent(name=\"researcher\", instructions=\"Research.\", model=\"gpt-5.2\")\nreviewer = af.Agent(name=\"reviewer\", instructions=\"Review. APPROVED or REJECTED.\", model=\"gpt-5.2\")\nrefiner = af.Agent(name=\"refiner\", instructions=\"Refine based on feedback.\", model=\"gpt-5.2\")\nresponder = af.Agent(name=\"responder\", instructions=\"Give final response.\", model=\"gpt-5.2\")\n\n\nasync def my_flow(user_message: str) -&gt; str:\n    # Internal classification - not saved to session\n    async with af.phase(\"Classification\"):\n        classification = await classifier(user_message).stream()\n\n    if \"COMPLEX\" in classification.upper():\n        # Internal research - not saved to session\n        async with af.phase(\"Research\"):\n            draft = await researcher(user_message).stream()\n    else:\n        draft = user_message\n\n    for attempt in range(3):\n        # Internal review - not saved to session\n        async with af.phase(f\"Review (attempt {attempt + 1})\"):\n            review = await reviewer(f\"Review:\\n{draft}\").stream()\n\n        if \"APPROVED\" in review.upper():\n            break\n\n        # Internal refinement - not saved to session\n        async with af.phase(f\"Refinement (attempt {attempt + 1})\"):\n            draft = await refiner(f\"Draft:\\n{draft}\\n\\nFeedback:\\n{review}\").stream()\n\n    # persist=True saves the final response to session\n    async with af.phase(\"Final Response\", persist=True):\n        return await responder(f\"Based on:\\n{draft}\").stream()\n</code></pre> <pre><code>\"\"\"Agentic Flow ChatKit Server - Minimal boilerplate.\"\"\"\n\nfrom agents import SQLiteSession\nfrom chatkit.server import ChatKitServer\n\nimport agentic_flow as af\n\nfrom .agenticflow_flow import my_flow\n\n\nclass MyServer(ChatKitServer):\n    async def respond(self, thread, item, context):\n        user_message = item.content[0].text if item else \"\"\n        session = SQLiteSession(session_id=thread.id, db_path=\"chat.db\")\n        runner = af.Runner(flow=my_flow, session=session)\n\n        async for event in af.chatkit.run_with_chatkit_context(\n            runner, thread, self.store, context, user_message\n        ):\n            yield event\n</code></pre> <pre><code>\"\"\"Agentic Flow CLI - Simple streaming handler.\"\"\"\n\nfrom agents import SQLiteSession\n\nimport agentic_flow as af\n\nfrom .agenticflow_flow import my_flow\n\n\ndef cli_handler(event):\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\n\nrunner = af.Runner(flow=my_flow, session=SQLiteSession(\"chat.db\"), handler=cli_handler)\nresult = runner.run_sync(\"Explain quantum computing\")\n</code></pre> Aspect Pure SDK AF Lines of code ~126 ~43 Phase management Manual Automatic Error handling try/finally Automatic Adding streaming Rewrite <code>.stream()</code>"},{"location":"#how-it-works-call-spec-discipline","title":"How It Works: Call-Spec Discipline","text":"<p>The secret is simple: separate declaration from execution.</p> <pre><code>import agentic_flow as af\n\nassistant = af.Agent(name=\"assistant\", instructions=\"Help the user.\", model=\"gpt-5.2\")\n\n# Declaration \u2014 creates a specification, NOT executed\nspec = assistant(\"Hello\")\n\n# Execution \u2014 happens here, and ONLY here\nresult = await spec\n</code></pre> Expression What it does Executes? <code>agent(prompt)</code> Creates <code>ExecutionSpec[T]</code>  No <code>.stream()</code> / <code>.silent()</code> / <code>.isolated()</code> Adds modifiers  No <code>await spec</code> Runs the agent Yes <p>This makes your code:</p> <ul> <li>Readable \u2014 Execution points visible by scanning for <code>await</code></li> <li>Debuggable \u2014 Set breakpoints at the single execution trigger</li> <li>Maintainable \u2014 Adding streaming is one modifier, not a structural rewrite</li> </ul> <p> Learn more about Call-Spec Discipline</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\nresearcher = af.Agent(name=\"researcher\", instructions=\"Research topics.\", model=\"gpt-5.2\")\nresponder = af.Agent(name=\"responder\", instructions=\"Respond to user.\", model=\"gpt-5.2\")\n\nasync def my_flow(user_message: str) -&gt; str:\n    # Internal thinking - not saved to session\n    async with af.phase(\"Research\"):\n        research = await researcher(user_message).stream()\n\n    # persist=True saves the final response to session\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Based on: {research}\").stream()\n\nrunner = af.Runner(flow=my_flow, session=SQLiteSession(\"chat.db\"))\nresult = await runner(\"What is Python?\")\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code># With uv (recommended)\nuv add ds-agentic-flow\n\n# With pip\npip install ds-agentic-flow\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Getting Started</p> <p>Install and run your first agent in 5 minutes</p> <p> Quickstart</p> </li> <li> <p> Concepts</p> <p>Deep dive into Call-Spec discipline</p> <p> Concepts</p> </li> <li> <p> Examples</p> <p>Multi-agent workflows, review loops, and more</p> <p> Examples</p> </li> <li> <p> API Reference</p> <p>Complete API documentation</p> <p> Reference</p> </li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>OpenAI Agents SDK</li> <li>ChatKit</li> </ul>"},{"location":"context-resolution/","title":"Context Resolution","text":""},{"location":"context-resolution/#overview","title":"Overview","text":"<p>AgenticFlow uses Python's <code>contextvars</code> module to manage execution context implicitly. This enables transparent context propagation without explicit parameter passing, allowing flows to access session, handler, and phase information from anywhere in the call stack.</p>"},{"location":"context-resolution/#available-contextvars","title":"Available ContextVars","text":"<p>AgenticFlow defines 6 contextvars across 3 modules:</p> ContextVar Module Purpose <code>current_session</code> <code>agentic_flow.agent</code> Current Session (conversation history) <code>current_handler</code> <code>agentic_flow.agent</code> Current event Handler (UI callbacks) <code>current_phase_session</code> <code>agentic_flow.agent</code> Current PhaseSession (inside phase with share_context=True) <code>current_in_phase</code> <code>agentic_flow.phase</code> Boolean flag: currently inside any phase() <code>current_phase_session_history</code> <code>agentic_flow.phase</code> Cached Session history (share_context=False) <code>current_chatkit_context</code> <code>agentic_flow.chatkit</code> ChatKit execution context"},{"location":"context-resolution/#resolution-priority","title":"Resolution Priority","text":"<p>When an agent executes, context is resolved in this priority order:</p> <pre><code>1. isolated=True        -&gt; No context (raw input, no session)\n2. phase(share_context=True)  -&gt; PhaseSession (inherited + accumulated)\n3. phase(share_context=False) -&gt; Cached Session history (read-only)\n4. Default (outside phase)    -&gt; Global Session from Runner\n</code></pre> <p>This hierarchy ensures:</p> <ul> <li>Isolation: <code>.isolated()</code> always runs without context</li> <li>Phase encapsulation: Phase internal thinking stays in PhaseSession</li> <li>Session integrity: Global Session is only written when explicitly intended</li> </ul>"},{"location":"context-resolution/#resolution-flow","title":"Resolution Flow","text":"<pre><code>graph TD\n    A(\".isolated()?\") --&gt;|\"Yes\"| B(\"No context \u2014 stateless\")\n    A --&gt;|\"No\"| C(\"In phase?\")\n    C --&gt;|\"Yes\"| D(\"Use PhaseSession\")\n    C --&gt;|\"No\"| E(\"Use Session\")</code></pre> <p>For a detailed explanation of how ExecutionSpec resolves context during execution, see ExecutionSpec: Context Resolution.</p>"},{"location":"context-resolution/#usage","title":"Usage","text":""},{"location":"context-resolution/#accessing-current-session","title":"Accessing Current Session","text":"<pre><code>from agentic_flow.agent import current_session\n\nasync def my_flow(user_message: str):\n    # Get current Session (may be None if not set by Runner)\n    session = current_session.get()\n    if session:\n        history = await session.get_items()\n        print(f\"History: {len(history)} messages\")\n\n    result = await agent(user_message).stream()\n    return result\n</code></pre>"},{"location":"context-resolution/#accessing-current-handler","title":"Accessing Current Handler","text":"<pre><code>from agentic_flow.agent import current_handler\n\nasync def my_flow(user_message: str):\n    handler = current_handler.get()\n    if handler:\n        # Handler receives SDK events and custom events\n        from agentic_flow.types import PhaseStarted\n        event = PhaseStarted(label=\"Custom Phase\")\n        result = handler(event)\n        if hasattr(result, \"__await__\"):\n            await result\n\n    result = await agent(user_message).stream()\n    return result\n</code></pre>"},{"location":"context-resolution/#accessing-current-phase-session","title":"Accessing Current Phase Session","text":"<pre><code>from agentic_flow.agent import current_phase_session\n\nasync def my_flow(user_message: str):\n    # Only available inside phase(share_context=True)\n    phase_session = current_phase_session.get()\n    if phase_session:\n        # Access phase info\n        print(f\"Phase: {phase_session.label}\")\n        items = await phase_session.get_items()\n        print(f\"Total items: {len(items)}\")\n\n        # Access custom phase data\n        phase_session.my_data = \"stored value\"\n        print(f\"Custom data: {phase_session.data}\")\n\n    result = await agent(user_message).stream()\n    return result\n</code></pre>"},{"location":"context-resolution/#debugging-current-context","title":"Debugging Current Context","text":"<pre><code>from agentic_flow.agent import (\n    current_session,\n    current_handler,\n    current_phase_session,\n)\nfrom agentic_flow.phase import current_in_phase\n\ndef debug_current_context():\n    \"\"\"Print current execution context state.\"\"\"\n    print(f\"Session: {current_session.get()}\")\n    print(f\"Handler: {current_handler.get()}\")\n    print(f\"PhaseSession: {current_phase_session.get()}\")\n    print(f\"In Phase: {current_in_phase.get()}\")\n</code></pre>"},{"location":"context-resolution/#how-context-is-injected","title":"How Context is Injected","text":""},{"location":"context-resolution/#by-runner","title":"By Runner","text":"<p>Runner sets <code>current_session</code> and <code>current_handler</code> when executing a flow:</p> <pre><code># Inside Runner.__call__()\nasync def __call__(self, user_message: str) -&gt; Any:\n    session_token = None\n    if self.session is not None:\n        session_token = current_session.set(self.session)\n\n    handler_token = None\n    if self.handler is not None:\n        handler_token = current_handler.set(self.handler)\n\n    try:\n        return await self.flow(user_message)\n    finally:\n        if handler_token is not None:\n            current_handler.reset(handler_token)\n        if session_token is not None:\n            current_session.reset(session_token)\n</code></pre>"},{"location":"context-resolution/#by-phase","title":"By phase()","text":"<p>The <code>phase()</code> context manager sets phase-specific context:</p> <pre><code>async with phase(\"Research\", share_context=True):\n    # current_phase_session is now set to a PhaseSession instance\n    # current_in_phase is True\n    result = await agent(user_message).stream()\n\n# After exiting:\n# current_phase_session is reset to None\n# current_in_phase is reset to False\n</code></pre> <p>For <code>share_context=False</code>:</p> <pre><code>async with phase(\"Research\", share_context=False):\n    # current_phase_session is None\n    # current_in_phase is True\n    # current_phase_session_history contains cached Session history\n    result = await agent(user_message).stream()\n</code></pre>"},{"location":"context-resolution/#by-run_with_chatkit_context","title":"By run_with_chatkit_context()","text":"<p>ChatKit integration sets <code>current_chatkit_context</code>:</p> <pre><code>async for event in run_with_chatkit_context(runner, thread, store, context, user_message):\n    # current_chatkit_context is set to ChatKitExecutionContext\n    # Enables workflow boundary management for reasoning display\n    yield event\n</code></pre>"},{"location":"context-resolution/#context-resolution-in-executionspec","title":"Context Resolution in ExecutionSpec","text":"<p><code>ExecutionSpec.resolve_input()</code> implements the resolution priority:</p> <pre><code>def resolve_input(self) -&gt; tuple[Any, Any]:\n    # 1. Isolated: no context\n    if self.is_isolated:\n        return self.input, None\n\n    # 2. Phase with share_context=True: use PhaseSession\n    phase_session = current_phase_session.get()\n    if phase_session is not None:\n        return self.input, phase_session  # SDK uses PhaseSession\n\n    # 3. Phase with share_context=False: read-only cached history\n    if current_in_phase.get():\n        cached_history = current_phase_session_history.get()\n        if cached_history is not None:\n            user_msg = {\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": self.input}]}\n            return list(cached_history) + [user_msg], None\n        return self.input, None\n\n    # 4. Default: global Session\n    session = current_session.get()\n    return self.input, session\n</code></pre>"},{"location":"context-resolution/#implementation-locations","title":"Implementation Locations","text":"Component Location ContextVar declarations (agent) <code>src/agentic_flow/agent.py:36-40</code> ContextVar declarations (phase) <code>src/agentic_flow/phase.py:33-39</code> ContextVar declarations (chatkit) <code>src/agentic_flow/chatkit.py:36-38</code> Context resolution <code>src/agentic_flow/agent.py:250-307</code> (<code>ExecutionSpec.resolve_input</code>) Runner injection <code>src/agentic_flow/runner.py:122-138</code> (<code>Runner.__call__</code>) Phase scoping <code>src/agentic_flow/phase.py:111-213</code> (<code>phase</code> context manager) ChatKit injection <code>src/agentic_flow/chatkit.py:182-287</code> (<code>run_with_chatkit_context</code>)"},{"location":"context-resolution/#best-practices","title":"Best Practices","text":""},{"location":"context-resolution/#do","title":"Do","text":"<ul> <li>Use <code>ContextVar.get()</code> to read context state</li> <li>Check for <code>None</code> before using context values</li> <li>Use contextvars for debugging and observability</li> </ul>"},{"location":"context-resolution/#do-not","title":"Do Not","text":"<ul> <li>Do not manually <code>set()</code> contextvars unless implementing a new execution container</li> <li>Do not rely on contextvar state across <code>await</code> boundaries in concurrent code</li> <li>Do not store mutable state in contextvars that could be shared unexpectedly</li> </ul>"},{"location":"context-resolution/#see-also","title":"See Also","text":"<ul> <li>Phase - Phase context management</li> <li>Flow &amp; Runner - Runner context injection</li> <li>Modifiers - <code>.isolated()</code> and context control</li> </ul>"},{"location":"concepts/","title":"Call-Spec Discipline","text":"<p>AF is built on a simple principle: separate declaration from execution.</p>"},{"location":"concepts/#the-core-insight","title":"The Core Insight","text":"<p>In agent systems, mixing \"what to do\" with \"when to do it\" creates cognitive load for both humans and LLMs. When a function call immediately triggers execution, you can't read the code to understand when side effects occur.</p> <p>AF addresses this by treating agent calls as specifications that only execute when explicitly awaited.</p>"},{"location":"concepts/#the-problem-why-call-spec-matters","title":"The Problem: Why Call-Spec Matters","text":""},{"location":"concepts/#pure-sdk-chatkit-the-boilerplate-problem","title":"Pure SDK + ChatKit: The Boilerplate Problem","text":"<p>Writing complex multi-agent flows with the Pure Agents SDK requires significant boilerplate:</p> Pure SDK \u2014 ~126 lines of ceremony <pre><code>\"\"\"Pure Agents SDK - Complex multi-agent with ChatKit streaming.\"\"\"\n\nimport asyncio\nfrom typing import Any\n\nfrom agents import Agent, ModelSettings, Runner\nfrom agents.extensions.chatkit import (\n    AgentContext,\n    close_workflow,\n    emit_phase_label,\n    stream_agent_response,\n)\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import StreamingResponse\nfrom openai.types.shared.reasoning import Reasoning\n\napp = FastAPI()\n\n\ndef create_agent(name: str, instructions: str) -&gt; Agent:\n    return Agent(\n        name=name,\n        instructions=instructions,\n        model=\"gpt-5.2\",\n        model_settings=ModelSettings(\n            store=True,\n            reasoning=Reasoning(effort=\"medium\", summary=\"auto\"),\n        ),\n    )\n\n\nclassifier = create_agent(\"classifier\", \"Classify as SIMPLE or COMPLEX.\")\nresearcher = create_agent(\"researcher\", \"Research the topic.\")\nreviewer = create_agent(\"reviewer\", \"Review. Reply APPROVED or REJECTED.\")\nrefiner = create_agent(\"refiner\", \"Refine based on feedback.\")\nresponder = create_agent(\"responder\", \"Give final response.\")\n\n\ndef to_messages(text: str) -&gt; list[dict[str, Any]]:\n    return [{\"role\": \"user\", \"content\": [{\"type\": \"input_text\", \"text\": text}]}]\n\n\n@app.post(\"/chatkit\")\nasync def chatkit_endpoint(request: Request):\n    body = await request.json()\n    messages = body.get(\"messages\", [])\n    user_input = messages[-1][\"content\"][0][\"text\"]\n\n    agent_context = AgentContext()\n    event_queue: asyncio.Queue = asyncio.Queue()\n\n    async def flow_logic():\n        try:\n            # Phase 1: Classification\n            emit_phase_label(agent_context, \"Classification\")\n            result = Runner.run_streamed(classifier, to_messages(user_input), context=agent_context)\n            async for event in stream_agent_response(agent_context, result):\n                await event_queue.put(event)\n            classification = result.final_output\n            await close_workflow(agent_context)\n\n            # Phase 2: Research (conditional)\n            if \"COMPLEX\" in classification.upper():\n                emit_phase_label(agent_context, \"Research\")\n                result = Runner.run_streamed(\n                    researcher, to_messages(user_input), context=agent_context\n                )\n                async for event in stream_agent_response(agent_context, result):\n                    await event_queue.put(event)\n                draft = result.final_output\n                await close_workflow(agent_context)\n            else:\n                draft = user_input\n\n            # Phase 3: Review loop\n            for attempt in range(3):\n                emit_phase_label(agent_context, f\"Review (attempt {attempt + 1})\")\n                result = Runner.run_streamed(\n                    reviewer, to_messages(f\"Review:\\n{draft}\"), context=agent_context\n                )\n                async for event in stream_agent_response(agent_context, result):\n                    await event_queue.put(event)\n                review = result.final_output\n                await close_workflow(agent_context)\n\n                if \"APPROVED\" in review.upper():\n                    break\n\n                emit_phase_label(agent_context, f\"Refinement (attempt {attempt + 1})\")\n                result = Runner.run_streamed(\n                    refiner,\n                    to_messages(f\"Draft:\\n{draft}\\n\\nFeedback:\\n{review}\"),\n                    context=agent_context,\n                )\n                async for event in stream_agent_response(agent_context, result):\n                    await event_queue.put(event)\n                draft = result.final_output\n                await close_workflow(agent_context)\n\n            # Phase 4: Final response\n            emit_phase_label(agent_context, \"Final Response\")\n            result = Runner.run_streamed(\n                responder, to_messages(f\"Based on:\\n{draft}\"), context=agent_context\n            )\n            async for event in stream_agent_response(agent_context, result):\n                await event_queue.put(event)\n            await close_workflow(agent_context)\n\n        except Exception:\n            try:\n                await close_workflow(agent_context)\n            except Exception:\n                pass\n            raise\n        finally:\n            await event_queue.put(None)\n\n    async def event_generator():\n        asyncio.create_task(flow_logic())\n        while True:\n            event = await event_queue.get()\n            if event is None:\n                break\n            yield f\"data: {event.model_dump_json()}\\n\\n\"\n\n    return StreamingResponse(event_generator(), media_type=\"text/event-stream\")\n</code></pre> <p>What's wrong with this?</p> <ul> <li> Manual <code>emit_phase_label()</code> + <code>close_workflow()</code> for every phase</li> <li> <code>async for event in stream_agent_response()</code> repeated everywhere</li> <li> <code>try/finally</code> blocks to ensure <code>close_workflow()</code> on errors</li> <li> af.Event queue management boilerplate</li> <li> Business logic buried in infrastructure code</li> </ul>"},{"location":"concepts/#the-solution-af","title":"The Solution: AF","text":"<p>The same workflow in AF:</p> Flow Definition \u2014 43 linesChatKit Server \u2014 20 linesCLI Usage \u2014 16 lines <pre><code>\"\"\"Agentic Flow - Same complex flow, clean code.\"\"\"\n\nimport agentic_flow as af\n\nclassifier = af.Agent(\n    name=\"classifier\",\n    instructions=\"Classify as SIMPLE or COMPLEX.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\nresearcher = af.Agent(name=\"researcher\", instructions=\"Research.\", model=\"gpt-5.2\")\nreviewer = af.Agent(name=\"reviewer\", instructions=\"Review. APPROVED or REJECTED.\", model=\"gpt-5.2\")\nrefiner = af.Agent(name=\"refiner\", instructions=\"Refine based on feedback.\", model=\"gpt-5.2\")\nresponder = af.Agent(name=\"responder\", instructions=\"Give final response.\", model=\"gpt-5.2\")\n\n\nasync def my_flow(user_message: str) -&gt; str:\n    # Internal classification - not saved to session\n    async with af.phase(\"Classification\"):\n        classification = await classifier(user_message).stream()\n\n    if \"COMPLEX\" in classification.upper():\n        # Internal research - not saved to session\n        async with af.phase(\"Research\"):\n            draft = await researcher(user_message).stream()\n    else:\n        draft = user_message\n\n    for attempt in range(3):\n        # Internal review - not saved to session\n        async with af.phase(f\"Review (attempt {attempt + 1})\"):\n            review = await reviewer(f\"Review:\\n{draft}\").stream()\n\n        if \"APPROVED\" in review.upper():\n            break\n\n        # Internal refinement - not saved to session\n        async with af.phase(f\"Refinement (attempt {attempt + 1})\"):\n            draft = await refiner(f\"Draft:\\n{draft}\\n\\nFeedback:\\n{review}\").stream()\n\n    # persist=True saves the final response to session\n    async with af.phase(\"Final Response\", persist=True):\n        return await responder(f\"Based on:\\n{draft}\").stream()\n</code></pre> <pre><code>\"\"\"Agentic Flow ChatKit Server - Minimal boilerplate.\"\"\"\n\nfrom agents import SQLiteSession\nfrom chatkit.server import ChatKitServer\n\nimport agentic_flow as af\n\nfrom .agenticflow_flow import my_flow\n\n\nclass MyServer(ChatKitServer):\n    async def respond(self, thread, item, context):\n        user_message = item.content[0].text if item else \"\"\n        session = SQLiteSession(session_id=thread.id, db_path=\"chat.db\")\n        runner = af.Runner(flow=my_flow, session=session)\n\n        async for event in af.chatkit.run_with_chatkit_context(\n            runner, thread, self.store, context, user_message\n        ):\n            yield event\n</code></pre> <pre><code>\"\"\"Agentic Flow CLI - Simple streaming handler.\"\"\"\n\nfrom agents import SQLiteSession\n\nimport agentic_flow as af\n\nfrom .agenticflow_flow import my_flow\n\n\ndef cli_handler(event):\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\n\nrunner = af.Runner(flow=my_flow, session=SQLiteSession(\"chat.db\"), handler=cli_handler)\nresult = runner.run_sync(\"Explain quantum computing\")\n</code></pre>"},{"location":"concepts/#side-by-side-comparison","title":"Side-by-Side Comparison","text":"Pure SDK AF <pre><code># Phase management\nemit_phase_label(ctx, \"Research\")\nresult = Runner.run_streamed(agent, msgs, context=ctx)\nasync for event in stream_agent_response(ctx, result):\n    await queue.put(event)\noutput = result.final_output\nawait close_workflow(ctx)\n</code></pre> <pre><code># Phase management\nasync with af.phase(\"Research\"):\n    output = await agent(msg).stream()\n</code></pre>  Pure SDK AF <pre><code># Error handling\ntry:\n    emit_phase_label(ctx, \"Work\")\n    # ... agent execution ...\n    await close_workflow(ctx)\nexcept Exception:\n    try:\n        await close_workflow(ctx)\n    except Exception:\n        pass\n    raise\n</code></pre> <pre><code># Error handling\nasync with af.phase(\"Work\"):\n    result = await agent(msg).stream()\n# Cleanup is automatic\n</code></pre>"},{"location":"concepts/#comparison-table","title":"Comparison Table","text":"Aspect Pure SDK AF Lines of code ~126 ~43 Phase management Manual <code>emit_phase_label</code> + <code>close_workflow</code> Automatic <code>async with af.phase()</code> Streaming <code>async for event in stream_agent_response()</code> <code>.stream()</code> Error handling Manual try/finally Automatic cleanup af.Event queue Manual management Handled internally Business logic Buried in boilerplate Clear and visible Adding streaming Structural rewrite Add <code>.stream()</code>"},{"location":"concepts/#declaration-vs-execution","title":"Declaration vs Execution","text":"<pre><code>import agentic_flow as af\n\nassistant = af.Agent(name=\"assistant\", instructions=\"Help the user.\", model=\"gpt-5.2\")\n\n# Declaration \u2014 creates a specification\nspec = assistant(\"What is Python?\")\n\n# Execution \u2014 runs the agent\nresult = await spec\n</code></pre> <p>The specification (<code>ExecutionSpec</code>) captures:</p> <ul> <li>Which agent to run</li> <li>What prompt to send</li> <li>How to run it (streaming, silent, isolated)</li> </ul> <p>Execution happens only when:</p> <ul> <li>You <code>await</code> the specification</li> </ul>"},{"location":"concepts/#the-five-axes","title":"The Five Axes","text":"<p>AF separates concerns into five orthogonal axes:</p> <pre><code>graph LR\n    subgraph WHAT[\"WHAT (Capabilities)\"]\n        A(prompt)\n        B(instructions)\n        C(tools)\n    end\n\n    subgraph WHERE[\"WHERE (Boundaries)\"]\n        D(session)\n        E(phase)\n        F(isolated)\n    end\n\n    subgraph HOW[\"HOW (Display)\"]\n        G(streaming)\n        H(silent)\n        I(handler)\n    end\n\n    subgraph LIMITS[\"LIMITS (Constraints)\"]\n        J(max_turns)\n        K(guardrails)\n    end\n\n    subgraph WHEN[\"WHEN (Lifecycle)\"]\n        L(hooks)\n        M(events)\n    end</code></pre> Axis Controls Specified At WHAT Agent capabilities <code>af.Agent(...)</code>, <code>agent(prompt)</code> WHERE Data flow boundaries <code>phase()</code>, <code>.isolated()</code>, <code>af.Runner(session=...)</code> HOW Display and observation <code>.stream()</code>, <code>.silent()</code>, <code>af.Runner(handler=...)</code> LIMITS Execution constraints <code>.max_turns()</code>, <code>.run_config()</code> WHEN Lifecycle observation <code>af.Agent(hooks=...)</code>, events"},{"location":"concepts/#what-agent-capabilities","title":"WHAT \u2014 Agent Capabilities","text":"<p>Defines what the agent can do:</p> <ul> <li><code>prompt</code> \u2014 The input message</li> <li><code>instructions</code> \u2014 System prompt</li> <li><code>tools</code> \u2014 Available tools</li> <li><code>output_type</code> \u2014 Structured output schema</li> <li><code>model</code>, <code>model_settings</code> \u2014 Model configuration</li> <li><code>handoffs</code> \u2014 Delegation targets</li> </ul>"},{"location":"concepts/#where-data-flow-boundaries","title":"WHERE \u2014 Data Flow Boundaries","text":"<p>Controls where data flows:</p> <ul> <li><code>Session</code> \u2014 Global conversation history</li> <li><code>PhaseSession</code> \u2014 Local thinking space</li> <li><code>.isolated()</code> \u2014 No context (stateless)</li> <li><code>Context</code> \u2014 Dependency injection (SDK pass-through via <code>.context()</code>)</li> </ul> <p>These are NOT hidden. You can explicitly access them:</p> <pre><code>from agentic_flow.agent import current_session, current_handler, current_phase_session\n\nasync def my_flow(user_message: str):\n    # Access current Session\n    session = current_session.get()\n    if session:\n        history = await session.get_items()\n        print(f\"History: {len(history)} messages\")\n\n    # Access current Handler\n    handler = current_handler.get()\n\n    # Access current PhaseSession (if inside phase)\n    phase_ctx = current_phase_session.get()\n\n    result = await agent(user_message).stream()\n    return result\n</code></pre> <p>AgenticFlow uses Python's <code>contextvars</code> to inject these dependencies. They are publicly accessible and documented.</p> <p> For details, see Context Resolution</p>"},{"location":"concepts/#how-display-and-observation","title":"HOW \u2014 Display and Observation","text":"<p>Controls how execution appears:</p> <ul> <li><code>.stream()</code> \u2014 Real-time events</li> <li><code>.silent()</code> \u2014 Suppress UI</li> <li><code>handler</code> \u2014 Custom event processing</li> <li><code>tracing</code> \u2014 Execution observation (SDK pass-through via <code>.run_config()</code>)</li> </ul>"},{"location":"concepts/#limits-execution-constraints","title":"LIMITS \u2014 Execution Constraints","text":"<p>Controls execution boundaries:</p> <ul> <li><code>.max_turns(n)</code> \u2014 Limit agent turns</li> <li><code>guardrails</code> \u2014 Input/output validation (SDK pass-through)</li> <li><code>tool_use_behavior</code> \u2014 Tool execution control (SDK pass-through)</li> </ul>"},{"location":"concepts/#when-lifecycle-observation","title":"WHEN \u2014 Lifecycle Observation","text":"<p>Observe execution lifecycle:</p> <ul> <li><code>PhaseStarted</code>, <code>PhaseEnded</code> \u2014 AF events</li> <li><code>AgentHooks</code> \u2014 Agent lifecycle (SDK pass-through)</li> <li><code>RunHooks</code> \u2014 Execution lifecycle (SDK pass-through)</li> </ul> <p>These axes don't mix</p> <p>You can't pass <code>stream=True</code> to <code>agent()</code>. You can't pass <code>handler</code> to <code>phase()</code>. This separation is enforced by the API.</p>"},{"location":"concepts/#the-single-execution-trigger","title":"The Single Execution Trigger","text":"<p>There is exactly one way to execute an agent: <code>await</code>.</p> <pre><code># These don't execute:\nspec = agent(\"prompt\")\nspec = agent(\"prompt\").stream()\nspec = agent(\"prompt\").silent().isolated()\n\n# This executes:\nresult = await spec\n</code></pre> <p>This makes execution points visible in your code. You can read a flow and know exactly where agents run.</p>"},{"location":"concepts/#modifiers-are-declarative","title":"Modifiers Are Declarative","text":"<p>Modifiers configure execution without triggering it:</p> <pre><code>spec = assistant(\"Hello\")          # ExecutionSpec\nspec = spec.stream()               # Still ExecutionSpec (with streaming flag)\nspec = spec.silent()               # Still ExecutionSpec (with silent flag)\nresult = await spec                # Now it executes\n</code></pre> <p>Modifier order doesn't matter</p> <pre><code>await agent(\"prompt\").stream().silent()    # Same as\nawait agent(\"prompt\").silent().stream()    # This\n</code></pre>"},{"location":"concepts/#boundaries-are-explicit","title":"Boundaries Are Explicit","text":"<p><code>phase()</code> creates explicit execution boundaries:</p> <pre><code>async with af.phase(\"Research\"):\n    # Boundary start is visible here\n    result = await researcher(query).stream()\n    # Boundary end is guaranteed (even on exception)\n</code></pre>"},{"location":"concepts/#why-this-matters","title":"Why This Matters","text":"<ul> <li> <p> For Humans</p> <ul> <li>Readable: Execution points visible by scanning for <code>await</code></li> <li>Debuggable: Set breakpoints at the single execution trigger</li> <li>Maintainable: Adding streaming is one modifier, not a rewrite</li> </ul> </li> <li> <p> For LLMs</p> <ul> <li>Predictable: No hidden state transitions to track</li> <li>Verifiable: Invariants can be checked (boundaries always close)</li> <li>Autonomous: Clearer code is easier for LLMs to understand</li> </ul> </li> </ul>"},{"location":"concepts/#summary","title":"Summary","text":"Principle Implementation Call \u2260 Execute <code>agent(prompt)</code> returns <code>ExecutionSpec</code>, not result Single trigger Only <code>await</code> executes Modifiers are flags <code>.stream()</code>, <code>.silent()</code>, <code>.isolated()</code>, <code>.max_turns()</code> don't execute Boundaries are visible <code>async with af.phase()</code> marks start/end Axes are separate WHAT / WHERE / HOW / LIMITS / WHEN don't mix <p>Next: ExecutionSpec </p>"},{"location":"concepts/execution-spec/","title":"ExecutionSpec","text":"<p><code>ExecutionSpec[T]</code> is the core abstraction that enables Call-Spec discipline. It represents an agent call that hasn't been executed yet.</p>"},{"location":"concepts/execution-spec/#what-executionspec-captures","title":"What ExecutionSpec Captures","text":"<p>When you call an agent, you get an <code>af.ExecutionSpec</code>:</p> <pre><code>spec = assistant(\"What is Python?\")\n</code></pre> <p>This spec captures:</p> Property Description Bound When Axis <code>sdk_agent</code> The underlying SDK Agent At creation WHAT <code>input</code> The prompt string At creation WHAT <code>streaming</code> Whether to stream events Via <code>.stream()</code> HOW <code>is_silent</code> Whether to suppress UI Via <code>.silent()</code> HOW <code>is_isolated</code> Whether to ignore context Via <code>.isolated()</code> WHERE <code>max_turns_sdk</code> Execution turn limit Via <code>.max_turns(n)</code> LIMITS <code>run_kwargs</code> SDK pass-through parameters Via modifiers Various"},{"location":"concepts/execution-spec/#what-executionspec-doesnt-capture","title":"What ExecutionSpec Doesn't Capture","text":"<p>The spec does not bind to the execution environment:</p> <ul> <li>Session \u2014 Resolved at <code>await</code> time from <code>current_session</code></li> <li>Handler \u2014 Resolved at <code>await</code> time from <code>current_handler</code></li> <li>Phase session \u2014 Resolved at <code>await</code> time from <code>current_phase_session</code></li> </ul> <p>This means you can create a spec in one context and execute it in another:</p> <pre><code>spec = assistant(\"Hello\")  # Created outside phase\n\nasync with af.phase(\"Greeting\"):\n    result = await spec    # Executed inside phase \u2014 uses phase context\n</code></pre>"},{"location":"concepts/execution-spec/#the-type-parameter","title":"The Type Parameter","text":"<p><code>af.ExecutionSpec[T]</code> is generic. <code>T</code> is determined by the Agent's <code>output_type</code>:</p> <pre><code># T = str (default)\nassistant = af.Agent(name=\"assistant\", instructions=\"...\", model=\"gpt-5.2\")\nspec: af.ExecutionSpec[str] = assistant(\"Hello\")\nresult: str = await spec\n\n# T = Analysis (Pydantic model)\nclass Analysis(BaseModel):\n    sentiment: str\n    score: float\n\nanalyzer = af.Agent(name=\"analyzer\", instructions=\"...\", output_type=Analysis, model=\"gpt-5.2\")\nspec: af.ExecutionSpec[Analysis] = analyzer(\"Analyze this text\")\nresult: Analysis = await spec\nresult.sentiment  # IDE completion works\n</code></pre>"},{"location":"concepts/execution-spec/#modifiers-return-executionspec","title":"Modifiers Return ExecutionSpec","text":"<p>Modifiers don't execute \u2014 they return a new <code>ExecutionSpec</code> with updated flags:</p> <pre><code>spec1 = assistant(\"Hello\")           # ExecutionSpec[str]\nspec2 = spec1.stream()               # ExecutionSpec[str] with streaming=True\nspec3 = spec2.silent()               # ExecutionSpec[str] with is_silent=True\nspec4 = spec3.max_turns(5)      # ExecutionSpec[str] with max_turns_sdk=5\n\n# spec1, spec2, spec3, spec4 are all unexecuted\n</code></pre> <p>Internally, modifiers use <code>dataclasses.replace</code>:</p> <pre><code>def stream(self) -&gt; ExecutionSpec[T]:\n    return replace(self, streaming=True)\n\ndef max_turns(self, max_turns: int) -&gt; ExecutionSpec[T]:\n    return replace(self, max_turns_sdk=max_turns)\n</code></pre>"},{"location":"concepts/execution-spec/#execution","title":"Execution","text":"<p>Execution happens in <code>__await__</code>:</p> <pre><code>def __await__(self):\n    return self.execute().__await__()\n</code></pre> <p>The <code>execute()</code> method:</p> <ol> <li>Resolves context (session, phase, handler)</li> <li>Runs the SDK Agent</li> <li>Updates phase context if applicable</li> <li>Returns <code>T</code></li> </ol>"},{"location":"concepts/execution-spec/#context-resolution","title":"Context Resolution","text":"<p>At execution time, <code>ExecutionSpec</code> resolves context in this order:</p> <pre><code>graph TD\n    A(\".isolated()?\") --&gt;|\"Yes\"| B(\"No context \u2014 stateless\")\n    A --&gt;|\"No\"| C(\"In phase?\")\n    C --&gt;|\"Yes\"| D(\"Use PhaseSession\")\n    C --&gt;|\"No\"| E(\"Use Session\")</code></pre> Context Session Read Session Write PhaseSession Outside phase Yes Yes (SDK) No Inside phase Inherited No Yes <code>phase(persist=True)</code> Inherited At phase end Yes <code>.isolated()</code> No No No <p>Accessing Context Explicitly</p> <p>You can explicitly access <code>current_session</code>, <code>current_handler</code>, and <code>current_phase_session</code> using Python's contextvars. For details, see Context Resolution.</p>"},{"location":"concepts/execution-spec/#streaming-execution","title":"Streaming Execution","text":"<p>When <code>streaming=True</code>, execution uses <code>Runner.run_streamed</code>:</p> <pre><code>async def execute_streaming(self, input_data, session) -&gt; T:\n    stream = Runner.run_streamed(self.sdk_agent, input_data, session=session)\n\n    async for event in stream.stream_events():\n        if handler and not self.is_silent:\n            handler(event)\n\n    return stream.final_output\n</code></pre> <p>Events are forwarded to the handler unless <code>.silent()</code> is set.</p>"},{"location":"concepts/execution-spec/#sdk-pass-through-modifiers","title":"SDK Pass-Through Modifiers","text":"<p>ExecutionSpec provides pass-through modifiers for SDK <code>Runner.run()</code> parameters:</p>"},{"location":"concepts/execution-spec/#run_config","title":".run_config()","text":"<p>Set RunConfig for execution:</p> <pre><code>from agents import RunConfig\n\n# Disable tracing\nresult = await agent(\"prompt\").run_config(\n    RunConfig(tracing_disabled=True)\n)\n\n# Override model for this execution\nresult = await agent(\"prompt\").run_config(\n    RunConfig(model=\"gpt-5.2-turbo\")\n)\n\n# Set workflow name for tracing\nresult = await agent(\"prompt\").run_config(\n    RunConfig(workflow_name=\"my_workflow\")\n)\n</code></pre>"},{"location":"concepts/execution-spec/#context","title":".context()","text":"<p>Inject context for dependency injection:</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass AppContext:\n    user_id: str\n    db: Database\n\nctx = AppContext(user_id=\"123\", db=db)\nresult = await agent(\"prompt\").context(ctx)\n</code></pre> <p>Context is local, not sent to LLM</p> <p>The context object is for local code only (tools, hooks). It is not included in prompts sent to the LLM.</p>"},{"location":"concepts/execution-spec/#run_kwarg","title":".run_kwarg()","text":"<p>Set arbitrary SDK parameters:</p> <pre><code># Conversation chaining\nresult = await agent(\"prompt\").run_kwarg(\n    previous_response_id=\"resp_abc123\",\n    conversation_id=\"conv_xyz\",\n)\n</code></pre>"},{"location":"concepts/execution-spec/#combining-pass-through-modifiers","title":"Combining Pass-Through Modifiers","text":"<p>All modifiers can be combined:</p> <pre><code>result = await agent(\"complex task\") \\\n    .max_turns(10) \\\n    .context(app_ctx) \\\n    .run_config(RunConfig(tracing_disabled=True)) \\\n    .stream()\n</code></pre>"},{"location":"concepts/execution-spec/#summary","title":"Summary","text":"<p><code>ExecutionSpec</code> embodies Call-Spec discipline:</p> <ul> <li>Declaration: Created by <code>agent(prompt)</code> \u2014 captures what to do</li> <li>Modifiers: <code>.stream()</code>, <code>.silent()</code>, <code>.isolated()</code>, <code>.max_turns(n)</code> \u2014 configure how</li> <li>SDK Pass-through: <code>.run_config()</code>, <code>.context()</code>, <code>.run_kwarg()</code> \u2014 SDK parameters</li> <li>Execution: <code>await</code> \u2014 runs the agent</li> <li>Context: Resolved at execution time \u2014 not bound at creation</li> </ul> <p>Next: Flow &amp; Runner </p>"},{"location":"concepts/flow-runner/","title":"Flow &amp; Runner","text":"<p>AF separates what your workflow does (Flow) from how it's executed (Runner).</p>"},{"location":"concepts/flow-runner/#flow-business-logic","title":"Flow: Business Logic","text":"<p>A Flow is a regular async Python function:</p> <pre><code>async def my_flow(user_message: str) -&gt; str:\n    async with af.phase(\"Research\"):\n        research = await researcher(user_message).stream()\n\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Based on: {research}\").stream()\n</code></pre> <p>Flow's responsibilities:</p> Responsibility Example Agent call order Which agents run in what sequence Control flow <code>if</code>, <code>for</code>, <code>while</code>, exception handling Data transformation Combining agent outputs Phase structure Where to put boundaries <p>Flow does NOT know about:</p> <ul> <li>Sessions \u2014 Injected by Runner</li> <li>Handlers \u2014 Injected by Runner</li> <li>ChatKit \u2014 Integrated at Runner level</li> </ul> <p>This separation keeps business logic clean.</p>"},{"location":"concepts/flow-runner/#runner-execution-environment","title":"Runner: Execution Environment","text":"<p>A Runner wraps a Flow and provides the execution environment:</p> <pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\nrunner = af.Runner(\n    flow=my_flow,\n    session=SQLiteSession(\"chat.db\"),\n    handler=my_handler,\n)\n\nresult = await runner(\"Hello!\")\n</code></pre> <p>Runner's responsibilities:</p> Responsibility How Session injection Via <code>contextvars</code> Handler injection Via <code>contextvars</code> Flow execution Calls <code>await self.flow(user_message)</code>"},{"location":"concepts/flow-runner/#how-injection-works","title":"How Injection Works","text":"<p>Runner uses Python's <code>contextvars</code> to inject dependencies:</p> <pre><code>async def __call__(self, user_message: str) -&gt; Any:\n    # Inject session\n    session_token = current_session.set(self.session)\n\n    # Inject handler\n    handler_token = current_handler.set(self.handler)\n\n    try:\n        return await self.flow(user_message)\n    finally:\n        # Clean up\n        current_handler.reset(handler_token)\n        current_session.reset(session_token)\n</code></pre> <p>This means:</p> <ul> <li>Flow code never sees <code>session</code> or <code>handler</code> directly</li> <li><code>af.ExecutionSpec.execute()</code> reads them from context when needed</li> <li>Context is properly scoped and cleaned up</li> </ul>"},{"location":"concepts/flow-runner/#synchronous-execution","title":"Synchronous Execution","text":"<p>Runner provides synchronous execution for scripts and Jupyter:</p> <pre><code># Option 1: run_sync()\nresult = runner.run_sync(\"Hello\")\n\n# Option 2: run().sync()\nresult = runner.run(\"Hello\").sync()\n</code></pre> <p>Both methods handle event loop creation appropriately:</p> <ul> <li>No running loop: Uses <code>asyncio.run()</code></li> <li>Running loop (Jupyter): Uses a thread pool</li> </ul> <p>sync() is a Runner adapter</p> <p><code>sync()</code> is NOT a third execution trigger for <code>af.ExecutionSpec</code>. It's a Runner-level convenience that internally awaits the flow.</p>"},{"location":"concepts/flow-runner/#working-without-runner","title":"Working Without Runner","text":"<p>You can use agents without Runner \u2014 they'll just lack session context:</p> <pre><code>import agentic_flow as af\n\nassistant = af.Agent(name=\"assistant\", instructions=\"...\", model=\"gpt-5.2\")\n\n# Works, but no session\nresult = await assistant(\"Hello\")\n</code></pre> <p>Each call is independent with no conversation history.</p>"},{"location":"concepts/flow-runner/#handler-pattern","title":"Handler Pattern","text":"<p>Handlers receive streaming events:</p> <pre><code>def my_handler(event):\n    # Check for text delta\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\n    # Or check event type\n    import agentic_flow as af\n    if isinstance(event, af.PhaseStarted):\n        print(f\"\\n[{event.label}]\")\n</code></pre> <p>Handlers are called for:</p> <ul> <li>SDK <code>StreamEvent</code> objects (reasoning, text delta, tool calls)</li> <li>AF events (<code>af.PhaseStarted</code>, <code>af.PhaseEnded</code>, <code>af.AgentResult</code>)</li> </ul>"},{"location":"concepts/flow-runner/#summary","title":"Summary","text":"Concept Role Flow Business logic \u2014 agent orchestration Runner Execution environment \u2014 session/handler injection Session Conversation history (from SDK) Handler Event receiver for streaming output contextvars Injection mechanism <pre><code>graph TB\n    subgraph Flow[\"Flow (Business Logic)\"]\n        A(Agent Calls)\n        B(phase Structure)\n        C(Python Control Flow)\n    end\n\n    subgraph Runner[\"Runner (Execution Environment)\"]\n        D(Session Injection)\n        E(Handler Injection)\n        F(ChatKit Integration)\n    end\n\n    Flow --&gt;|\"injected into\"| Runner</code></pre> <p>Next: Phase </p>"},{"location":"concepts/modifiers/","title":"Modifiers","text":"<p>Modifiers configure execution behavior without triggering execution. They return a new <code>ExecutionSpec</code> with updated flags.</p>"},{"location":"concepts/modifiers/#modifier-categories","title":"Modifier Categories","text":"Axis Modifiers Purpose WHERE <code>.isolated()</code> Ignore all context HOW <code>.stream()</code>, <code>.silent()</code> Control display LIMITS <code>.max_turns(n)</code> Limit execution SDK <code>.run_config()</code>, <code>.context()</code>, <code>.run_kwarg()</code> SDK parameters"},{"location":"concepts/modifiers/#where-axis","title":"WHERE Axis","text":""},{"location":"concepts/modifiers/#isolated","title":".isolated()","text":"<p>Executes without any context \u2014 no Session, no PhaseSession.</p> <pre><code>result = await translator(\"Hello\").isolated()\n</code></pre> <p>What isolated means:</p> <ul> <li>Does NOT read from Session</li> <li>Does NOT write to Session</li> <li>Ignores PhaseSession entirely</li> <li>Completely stateless execution</li> </ul> <p>Use cases:</p> <ul> <li>Pure transformations (translation, formatting)</li> <li>Parallel execution (<code>asyncio.gather</code>)</li> <li>Temporary evaluation</li> <li>Stateless operations</li> </ul> <pre><code># Safe parallel execution\nresults = await asyncio.gather(\n    search(\"topic A\").isolated(),\n    search(\"topic B\").isolated(),\n    search(\"topic C\").isolated(),\n)\n</code></pre>"},{"location":"concepts/modifiers/#how-axis","title":"HOW Axis","text":""},{"location":"concepts/modifiers/#stream","title":".stream()","text":"<p>Enables streaming mode. Events are forwarded to the handler as they arrive.</p> <pre><code>result = await assistant(\"Hello\").stream()\n</code></pre> <p>What streaming enables:</p> <ul> <li>Real-time text display in CLI or web UI</li> <li>Reasoning step visibility</li> <li>Tool call notifications</li> <li>Progress indication</li> </ul> <p>Without streaming:</p> <pre><code>result = await assistant(\"Hello\")\n# Handler receives only the final AgentResult\n</code></pre>"},{"location":"concepts/modifiers/#silent","title":".silent()","text":"<p>Suppresses UI display. The agent still executes normally.</p> <pre><code>result = await assistant(\"Background task\").silent()\n</code></pre> <p>What .silent() affects:</p> <ul> <li>Handler event forwarding (disabled)</li> <li>ChatKit event queue (disabled)</li> </ul> <p>What .silent() does NOT affect:</p> <ul> <li>PhaseSession writes (still happens)</li> <li>Execution itself (agent runs normally)</li> <li>Return value (still returns <code>T</code>)</li> </ul> <p>Use cases:</p> <ul> <li>Background processing</li> <li>Internal tool calls</li> <li>Implementation details that shouldn't appear in UI</li> </ul> <p>Phase label still displays</p> <p><code>.silent()</code> controls visibility at the agent call level. The <code>phase()</code> label itself is a UX boundary and still displays in ChatKit.</p> <pre><code>async with af.phase(\"Research\"):  # \u2190 Label appears in UI\n    r = await agent(msg).silent().stream()  # \u2190 Output hidden\n</code></pre>"},{"location":"concepts/modifiers/#limits-axis","title":"LIMITS Axis","text":""},{"location":"concepts/modifiers/#max_turns","title":".max_turns()","text":"<p>Limits the number of turns the agent can take during execution.</p> <pre><code>result = await agent(\"Complex task\").max_turns(5)\n</code></pre> <p>What max_turns controls:</p> <ul> <li>Maximum number of LLM invocations within a single agent run</li> <li>Tool call loops and handoff chains count toward this limit</li> <li>Once the limit is reached, execution stops</li> </ul> <p>Use cases:</p> <ul> <li>Preventing runaway tool call loops</li> <li>Controlling costs in complex agent workflows</li> <li>Setting guardrails for autonomous agent behavior</li> </ul> <pre><code># Limit tool calls for safety\nresult = await researcher(\"Find information\").max_turns(10).stream()\n\n# Strict limit for simple tasks\nresult = await formatter(\"Format this text\").max_turns(1)\n</code></pre> <p>SDK Pass-through</p> <p>This modifier maps directly to the <code>max_turns</code> parameter of <code>Runner.run()</code> in the OpenAI Agents SDK. It controls execution behavior at the SDK level.</p>"},{"location":"concepts/modifiers/#sdk-pass-through-modifiers","title":"SDK Pass-Through Modifiers","text":"<p>These modifiers pass parameters directly to SDK's <code>Runner.run()</code>:</p>"},{"location":"concepts/modifiers/#run_config","title":".run_config()","text":"<p>Configure execution with RunConfig:</p> <pre><code>from agents import RunConfig\n\n# Disable tracing for this execution\nresult = await agent(\"prompt\").run_config(\n    RunConfig(tracing_disabled=True)\n).stream()\n\n# Override model for this execution\nresult = await agent(\"prompt\").run_config(\n    RunConfig(model=\"gpt-5.2-turbo\")\n)\n\n# Set workflow name for tracing\nresult = await agent(\"prompt\").run_config(\n    RunConfig(workflow_name=\"my_workflow\")\n)\n</code></pre>"},{"location":"concepts/modifiers/#context","title":".context()","text":"<p>Inject context for dependency injection:</p> <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass AppContext:\n    user_id: str\n    api_key: str\n    logger: Logger\n\nctx = AppContext(user_id=\"123\", api_key=\"...\", logger=logger)\n\n# Context is available in tools and hooks\nresult = await agent(\"prompt\").context(ctx).stream()\n</code></pre> <p>Context is local, not sent to LLM</p> <p>The context object is for local code only. It is not included in prompts.</p>"},{"location":"concepts/modifiers/#run_kwarg","title":".run_kwarg()","text":"<p>Set arbitrary SDK parameters:</p> <pre><code># Conversation chaining\nresult = await agent(\"prompt\").run_kwarg(\n    previous_response_id=\"resp_abc123\",\n    conversation_id=\"conv_xyz\",\n)\n</code></pre>"},{"location":"concepts/modifiers/#combining-modifiers","title":"Combining Modifiers","text":"<p>Modifiers can be combined. Order doesn't matter.</p> <pre><code># All equivalent:\nawait agent(\"prompt\").stream().silent()\nawait agent(\"prompt\").silent().stream()\n\n# All equivalent:\nawait agent(\"prompt\").stream().isolated()\nawait agent(\"prompt\").isolated().stream()\n\n# Across axes:\nawait agent(\"prompt\").stream().silent().isolated()\n\n# With execution limit:\nawait agent(\"prompt\").stream().max_turns(5)\nawait agent(\"prompt\").max_turns(5).stream()  # Same result\n\n# Full combination with SDK pass-through:\nawait agent(\"complex task\") \\\n    .max_turns(10) \\\n    .context(app_ctx) \\\n    .run_config(RunConfig(tracing_disabled=True)) \\\n    .stream()\n</code></pre>"},{"location":"concepts/modifiers/#modifier-summary-table","title":"Modifier Summary Table","text":"Modifier Axis UI Display PhaseSession Session Execution <code>.stream()</code> HOW Streaming Yes Yes Normal <code>.silent()</code> HOW No Yes Yes Normal <code>.isolated()</code> WHERE No No No Normal <code>.max_turns(n)</code> LIMITS Yes Yes Yes Limited <code>.run_config(cfg)</code> SDK Yes Yes Yes Configured <code>.context(ctx)</code> SDK Yes Yes Yes With DI <code>.run_kwarg(**kw)</code> SDK Yes Yes Yes Configured"},{"location":"concepts/modifiers/#implementation","title":"Implementation","text":"<p>Modifiers use <code>dataclasses.replace</code> to create new specs:</p> <pre><code>def stream(self) -&gt; ExecutionSpec[T]:\n    return replace(self, streaming=True)\n\ndef silent(self) -&gt; ExecutionSpec[T]:\n    return replace(self, is_silent=True)\n\ndef isolated(self) -&gt; ExecutionSpec[T]:\n    return replace(self, is_isolated=True)\n\ndef max_turns(self, max_turns: int) -&gt; ExecutionSpec[T]:\n    return replace(self, max_turns_sdk=max_turns)\n\ndef run_config(self, run_config: RunConfig) -&gt; ExecutionSpec[T]:\n    new_kwargs = {**self.run_kwargs, \"run_config\": run_config}\n    return replace(self, run_kwargs=new_kwargs)\n\ndef context(self, context: Any) -&gt; ExecutionSpec[T]:\n    new_kwargs = {**self.run_kwargs, \"context\": context}\n    return replace(self, run_kwargs=new_kwargs)\n\ndef run_kwarg(self, **kwargs: Any) -&gt; ExecutionSpec[T]:\n    new_kwargs = {**self.run_kwargs, **kwargs}\n    return replace(self, run_kwargs=new_kwargs)\n</code></pre> <p>This ensures:</p> <ul> <li>Original spec is unchanged</li> <li>New spec is a separate object</li> <li>Specs can be reused</li> </ul>"},{"location":"concepts/modifiers/#anti-patterns","title":"Anti-Patterns","text":"<p>Don't pass modifiers as arguments:</p> <pre><code># Wrong \u2014 TypeError\nawait agent(\"prompt\", stream=True)\nawait agent(\"prompt\", isolated=True)\n\n# Correct\nawait agent(\"prompt\").stream()\nawait agent(\"prompt\").isolated()\n</code></pre> <p>Don't call modifiers on Agent directly:</p> <pre><code># Wrong \u2014 TypeError\nawait agent.stream(\"prompt\")\n\n# Correct\nawait agent(\"prompt\").stream()\n</code></pre> <p>These restrictions enforce the Call-Spec discipline: modifiers are on the spec, not the call.</p> <p>Next: Streaming Guide </p>"},{"location":"concepts/phase/","title":"Phase","text":"<p><code>phase()</code> creates semantic boundaries in your workflow. It's where internal thinking happens \u2014 separate from user-facing conversation history.</p>"},{"location":"concepts/phase/#basic-usage","title":"Basic Usage","text":"<pre><code>import agentic_flow as af\n\nasync def my_flow(user_message: str) -&gt; str:\n    async with af.phase(\"Research\"):\n        result = await researcher(user_message).stream()\n    return result\n</code></pre>"},{"location":"concepts/phase/#what-phase-does","title":"What phase() Does","text":"<ol> <li>Creates a boundary \u2014 Marks the start and end of a logical unit</li> <li>Manages context \u2014 Creates a temporary <code>PhaseSession</code> for agent calls</li> <li>Emits events \u2014 Sends <code>PhaseStarted</code>/<code>PhaseEnded</code> to handlers</li> <li>Integrates with ChatKit \u2014 Creates workflow boundaries for UI display</li> <li>Guarantees cleanup \u2014 Even on exceptions, the boundary closes</li> </ol>"},{"location":"concepts/phase/#parameters","title":"Parameters","text":"<pre><code>async with af.phase(\n    label=\"Research\",       # Display name (required)\n    share_context=True,     # Create af.PhaseSession (default: True)\n    persist=False,          # Write to Session at end (default: False)\n):\n    ...\n</code></pre> Parameter Default Description <code>label</code> (required) Name displayed in UI and passed to handlers <code>share_context</code> <code>True</code> Create <code>PhaseSession</code> for agent history sharing <code>persist</code> <code>False</code> Write last agent result to Session when phase ends"},{"location":"concepts/phase/#context-behavior","title":"Context Behavior","text":""},{"location":"concepts/phase/#default-internal-thinking","title":"Default: Internal Thinking","text":"<pre><code>async with af.phase(\"Research\"):\n    r1 = await agent(\"query 1\").stream()  # Recorded in af.PhaseSession\n    r2 = await agent(\"query 2\").stream()  # Sees r1's context\n    # Nothing written to Session\n</code></pre> <p>History within the phase is discarded when the phase ends. This is intentional \u2014 internal thinking shouldn't pollute user-facing history.</p>"},{"location":"concepts/phase/#persisttrue-save-to-session","title":"persist=True: Save to Session","text":"<pre><code>async with af.phase(\"Response\", persist=True):\n    r1 = await agent(\"draft\").stream()\n    r2 = await agent(\"refine\").stream()\n    # Last user/assistant pair written to Session\n</code></pre> <p>Only the last exchange is persisted. Intermediate steps remain internal.</p>"},{"location":"concepts/phase/#share_contextfalse-isolated-read","title":"share_context=False: Isolated Read","text":"<pre><code>async with af.phase(\"Classification\", share_context=False):\n    result = await classifier(message).stream()\n    # Can read Session history, but no af.PhaseSession\n    # No write to Session\n</code></pre> <p>Use this when you need session history but don't want agents to share context within the phase.</p>"},{"location":"concepts/phase/#phasesession","title":"PhaseSession","text":"<p>When <code>share_context=True</code>, a <code>PhaseSession</code> is created. It implements SDK's <code>SessionABC</code> protocol:</p> <pre><code>async with af.phase(\"Research\") as ctx:\n    await agent(\"query 1\").stream()\n    await agent(\"query 2\").stream()\n\n    # Access phase data\n    ctx.my_data = \"something\"\n    print(ctx.my_data)\n</code></pre> <p><code>PhaseSession</code> provides:</p> <ul> <li><code>inherited_history</code>: Session history at phase start (read-only)</li> <li><code>items</code>: Messages within the phase (SDK-managed)</li> <li><code>data</code>: Arbitrary data storage (accessible via attributes)</li> <li><code>get_items()</code>: Returns <code>inherited_history + items</code> (async)</li> </ul>"},{"location":"concepts/phase/#session-inheritance","title":"Session Inheritance","text":"<p>Phases inherit session history at creation time:</p> <pre><code># Session has: [user: \"Hi\", assistant: \"Hello\"]\n\nasync with af.phase(\"Research\"):\n    # Agent sees: \"Hi\" \u2192 \"Hello\" (from Session)\n    await agent(\"query\").stream()\n    # Agent sees: \"Hi\" \u2192 \"Hello\" + \"query\" \u2192 response\n</code></pre> <p>This allows agents within a phase to see past conversation while keeping their internal work separate.</p>"},{"location":"concepts/phase/#nesting","title":"Nesting","text":"<p>Phases can be nested, but each creates its own context:</p> <pre><code>async with af.phase(\"Outer\"):\n    await agent(\"outer query\").stream()\n\n    async with af.phase(\"Inner\"):\n        await agent(\"inner query\").stream()\n        # Has its own af.PhaseSession\n</code></pre>"},{"location":"concepts/phase/#event-flow","title":"Event Flow","text":"<p>Phases emit events to handlers:</p> <pre><code>import agentic_flow as af\n\ndef my_handler(event):\n    if isinstance(event, af.PhaseStarted):\n        print(f\"Starting: {event.label}\")\n    elif isinstance(event, af.PhaseEnded):\n        print(f\"Ended: {event.label} ({event.elapsed_ms}ms)\")\n</code></pre>"},{"location":"concepts/phase/#chatkit-integration","title":"ChatKit Integration","text":"<p>In ChatKit mode, phases create workflow boundaries:</p> <pre><code>graph LR\n    A(Phase Start) --&gt;|\"emit_phase_label()\"| B(Workflow Boundary)\n    B --&gt; C(Agent Execution)\n    C --&gt; D(Reasoning Display)\n    D --&gt;|\"close_workflow()\"| E(Phase End)</code></pre> <p>Each phase gets its own \"workflow\" in the ChatKit UI, which enables:</p> <ul> <li>Independent reasoning display per phase</li> <li>Clear visual separation of phases</li> <li>Collapsible phase sections</li> </ul>"},{"location":"concepts/phase/#summary","title":"Summary","text":"Aspect Behavior Default Internal thinking, discarded at phase end <code>persist=True</code> Last exchange saved to Session <code>share_context=False</code> Read Session, no PhaseSession Cleanup Guaranteed even on exception Inheritance Session history available to agents Events <code>af.PhaseStarted</code> / <code>af.PhaseEnded</code> emitted <p>Next: Modifiers </p>"},{"location":"examples/multi-agent/","title":"Multi-Agent Workflow","text":"<p>This example demonstrates a multi-agent research workflow with classification, research, and response phases.</p>"},{"location":"examples/multi-agent/#overview","title":"Overview","text":"<pre><code>graph LR\n    A(User Message) --&gt; B(Classifier)\n    B --&gt;|SIMPLE| C(Responder)\n    B --&gt;|COMPLEX| D(Researcher)\n    D --&gt; E(Responder)\n    C --&gt; F(Response)\n    E --&gt; F</code></pre>"},{"location":"examples/multi-agent/#complete-example","title":"Complete Example","text":"<pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\n# Define agents\nclassifier = af.Agent(\n    name=\"classifier\",\n    instructions=\"\"\"Classify the user's request as SIMPLE or COMPLEX.\n    SIMPLE: Greetings, simple questions, basic information\n    COMPLEX: Research questions, analysis, comparisons\n    Respond with only SIMPLE or COMPLEX.\"\"\",\n    model=\"gpt-5.2\",\n)\n\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"\"\"Research the given topic thoroughly.\n    Provide detailed findings with sources when possible.\"\"\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\n\nresponder = af.Agent(\n    name=\"responder\",\n    instructions=\"\"\"Provide a clear, helpful response to the user.\n    If research findings are provided, base your response on them.\"\"\",\n    model=\"gpt-5.2\",\n)\n\n\nasync def multi_agent_flow(user_message: str) -&gt; str:\n    # Phase 1: Classification\n    async with af.phase(\"Classification\"):\n        classification = await classifier(user_message).stream()\n\n    # Phase 2: Research (conditional)\n    if \"COMPLEX\" in classification.upper():\n        async with af.phase(\"Research\"):\n            research = await researcher(user_message).stream()\n        context = f\"Research findings:\\n{research}\"\n    else:\n        context = f\"User message:\\n{user_message}\"\n\n    # Phase 3: Response\n    async with af.phase(\"Response\", persist=True):\n        return await responder(context).stream()\n\n\n# Run\nrunner = af.Runner(\n    flow=multi_agent_flow,\n    session=SQLiteSession(\"multi_agent.db\"),\n)\n\nresult = runner.run_sync(\"What are the key differences between REST and GraphQL?\")\nprint(result)\n</code></pre>"},{"location":"examples/multi-agent/#key-points","title":"Key Points","text":""},{"location":"examples/multi-agent/#conditional-branching","title":"Conditional Branching","text":"<p>Standard Python <code>if</code> statements control flow:</p> <pre><code>if \"COMPLEX\" in classification.upper():\n    async with af.phase(\"Research\"):\n        research = await researcher(user_message).stream()\n</code></pre>"},{"location":"examples/multi-agent/#phase-structure","title":"Phase Structure","text":"<ul> <li>Classification: Quick categorization</li> <li>Research: Deep analysis (only for complex queries)</li> <li>Response: User-facing answer (persisted)</li> </ul>"},{"location":"examples/multi-agent/#data-flow","title":"Data Flow","text":"<p>Agent outputs flow through Python variables:</p> <pre><code>classification = await classifier(msg).stream()  # str\nresearch = await researcher(msg).stream()        # str\nresponse = await responder(context).stream()     # str\n</code></pre>"},{"location":"examples/multi-agent/#with-typed-output","title":"With Typed Output","text":"<p>Use Pydantic models for structured data:</p> <pre><code>from pydantic import BaseModel\n\nclass Classification(BaseModel):\n    category: str  # \"SIMPLE\" or \"COMPLEX\"\n    confidence: float\n    reason: str\n\nclassifier = af.Agent(\n    name=\"classifier\",\n    instructions=\"Classify the request.\",\n    output_type=Classification,\n    model=\"gpt-5.2\",\n)\n\nasync def typed_flow(user_message: str) -&gt; str:\n    async with af.phase(\"Classification\"):\n        result: Classification = await classifier(user_message).stream()\n\n    if result.category == \"COMPLEX\" and result.confidence &gt; 0.7:\n        async with af.phase(\"Research\"):\n            research = await researcher(user_message).stream()\n        context = f\"Research:\\n{research}\"\n    else:\n        context = user_message\n\n    async with af.phase(\"Response\", persist=True):\n        return await responder(context).stream()\n</code></pre>"},{"location":"examples/multi-agent/#with-handler","title":"With Handler","text":"<p>Add streaming output for CLI:</p> <pre><code>import agentic_flow as af\n\ndef cli_handler(event):\n    if isinstance(event, af.PhaseStarted):\n        print(f\"\\n[{event.label}]\")\n    elif isinstance(event, af.PhaseEnded):\n        print(f\"\\n[/{event.label}]\")\n    elif hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\nrunner = af.Runner(\n    flow=multi_agent_flow,\n    session=SQLiteSession(\"multi_agent.db\"),\n    handler=cli_handler,\n)\n</code></pre>"},{"location":"examples/multi-agent/#parallel-research","title":"Parallel Research","text":"<p>For independent research tasks, use <code>asyncio.gather</code> with <code>.isolated()</code>:</p> <pre><code>import asyncio\n\nasync def parallel_research_flow(user_message: str) -&gt; str:\n    async with af.phase(\"Classification\"):\n        classification = await classifier(user_message).stream()\n\n    if \"COMPLEX\" in classification.upper():\n        async with af.phase(\"Research\"):\n            # Parallel research on different aspects\n            results = await asyncio.gather(\n                researcher(f\"Technical aspects of: {user_message}\").isolated(),\n                researcher(f\"Practical applications of: {user_message}\").isolated(),\n                researcher(f\"Comparisons and alternatives for: {user_message}\").isolated(),\n            )\n            research = \"\\n\\n\".join(results)\n    else:\n        research = user_message\n\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Based on research:\\n{research}\").stream()\n</code></pre> <p>Next: Review Loop </p>"},{"location":"examples/review-loop/","title":"Review Loop","text":"<p>This example demonstrates an iterative review and refinement workflow where content is improved until approved.</p>"},{"location":"examples/review-loop/#overview","title":"Overview","text":"<pre><code>graph TD\n    A(User Message) --&gt; B(Drafter)\n    B --&gt; C(Reviewer)\n    C --&gt;|APPROVED| D(Final Response)\n    C --&gt;|REJECTED| E(Refiner)\n    E --&gt; C</code></pre>"},{"location":"examples/review-loop/#complete-example","title":"Complete Example","text":"<pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\n# Define agents\ndrafter = af.Agent(\n    name=\"drafter\",\n    instructions=\"\"\"Create an initial draft response to the user's request.\n    Be thorough but expect feedback for improvement.\"\"\",\n    model=\"gpt-5.2\",\n)\n\nreviewer = af.Agent(\n    name=\"reviewer\",\n    instructions=\"\"\"Review the draft critically.\n    If acceptable, respond with: APPROVED\n    If needs improvement, respond with: REJECTED\n    Followed by specific feedback on what to improve.\"\"\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\n\nrefiner = af.Agent(\n    name=\"refiner\",\n    instructions=\"\"\"Improve the draft based on the reviewer's feedback.\n    Address each point of feedback specifically.\"\"\",\n    model=\"gpt-5.2\",\n)\n\n\nasync def review_loop_flow(user_message: str, max_iterations: int = 3) -&gt; str:\n    # Phase 1: Initial draft\n    async with af.phase(\"Drafting\"):\n        draft = await drafter(user_message).stream()\n\n    # Phase 2-N: Review and refine loop\n    for attempt in range(max_iterations):\n        async with af.phase(f\"Review (attempt {attempt + 1})\"):\n            review = await reviewer(\n                f\"Draft:\\n{draft}\\n\\nPlease review this draft.\"\n            ).stream()\n\n        if \"APPROVED\" in review.upper():\n            break\n\n        async with af.phase(f\"Refinement (attempt {attempt + 1})\"):\n            draft = await refiner(\n                f\"Original request:\\n{user_message}\\n\\n\"\n                f\"Current draft:\\n{draft}\\n\\n\"\n                f\"Feedback:\\n{review}\"\n            ).stream()\n\n    # Final phase\n    async with af.phase(\"Final Response\", persist=True):\n        return draft\n\n\n# Run\nrunner = af.Runner(\n    flow=review_loop_flow,\n    session=SQLiteSession(\"review_loop.db\"),\n)\n\nresult = runner.run_sync(\"Write a professional email declining a job offer\")\nprint(result)\n</code></pre>"},{"location":"examples/review-loop/#key-points","title":"Key Points","text":""},{"location":"examples/review-loop/#loop-pattern","title":"Loop Pattern","text":"<p>Standard Python <code>for</code> loop with early exit:</p> <pre><code>for attempt in range(max_iterations):\n    review = await reviewer(draft).stream()\n    if \"APPROVED\" in review.upper():\n        break\n    draft = await refiner(draft, review).stream()\n</code></pre>"},{"location":"examples/review-loop/#dynamic-phase-labels","title":"Dynamic Phase Labels","text":"<p>Phase labels can be dynamic:</p> <pre><code>async with af.phase(f\"Review (attempt {attempt + 1})\"):\n    ...\n</code></pre>"},{"location":"examples/review-loop/#data-accumulation","title":"Data Accumulation","text":"<p>The draft evolves through iterations:</p> <pre><code>draft = await drafter(message).stream()      # Initial\ndraft = await refiner(draft, feedback).stream()  # Refined\ndraft = await refiner(draft, feedback).stream()  # Further refined\n</code></pre>"},{"location":"examples/review-loop/#with-typed-review","title":"With Typed Review","text":"<p>Use structured output for clearer review decisions:</p> <pre><code>from pydantic import BaseModel\n\nclass Review(BaseModel):\n    approved: bool\n    feedback: str | None = None\n    issues: list[str] = []\n\nreviewer = af.Agent(\n    name=\"reviewer\",\n    instructions=\"Review the draft. Provide structured feedback.\",\n    output_type=Review,\n    model=\"gpt-5.2\",\n)\n\nasync def typed_review_flow(user_message: str) -&gt; str:\n    async with af.phase(\"Drafting\"):\n        draft = await drafter(user_message).stream()\n\n    for attempt in range(3):\n        async with af.phase(f\"Review {attempt + 1}\"):\n            review: Review = await reviewer(f\"Draft:\\n{draft}\").stream()\n\n        if review.approved:\n            break\n\n        if review.issues:\n            feedback = \"\\n\".join(f\"- {issue}\" for issue in review.issues)\n        else:\n            feedback = review.feedback or \"General improvements needed\"\n\n        async with af.phase(f\"Refinement {attempt + 1}\"):\n            draft = await refiner(\n                f\"Draft:\\n{draft}\\n\\nIssues:\\n{feedback}\"\n            ).stream()\n\n    async with af.phase(\"Final\", persist=True):\n        return draft\n</code></pre>"},{"location":"examples/review-loop/#with-quality-threshold","title":"With Quality Threshold","text":"<p>Add a quality score to control iteration:</p> <pre><code>class QualityReview(BaseModel):\n    score: float  # 0-10\n    approved: bool\n    feedback: str\n\nasync def quality_review_flow(user_message: str, threshold: float = 8.0) -&gt; str:\n    async with af.phase(\"Drafting\"):\n        draft = await drafter(user_message).stream()\n\n    for attempt in range(5):\n        async with af.phase(f\"Quality Check {attempt + 1}\"):\n            review: QualityReview = await reviewer(f\"Draft:\\n{draft}\").stream()\n\n        if review.approved and review.score &gt;= threshold:\n            break\n\n        async with af.phase(f\"Improvement {attempt + 1}\"):\n            draft = await refiner(\n                f\"Score: {review.score}/10\\n\"\n                f\"Target: {threshold}/10\\n\"\n                f\"Feedback: {review.feedback}\\n\"\n                f\"Draft:\\n{draft}\"\n            ).stream()\n\n    async with af.phase(\"Final\", persist=True):\n        return draft\n</code></pre>"},{"location":"examples/review-loop/#streaming-progress","title":"Streaming Progress","text":"<p>Show progress with a handler:</p> <pre><code>import agentic_flow as af\n\ndef progress_handler(event):\n    if isinstance(event, af.PhaseStarted):\n        if \"Review\" in event.label:\n            print(f\"\\nReviewing...\")\n        elif \"Refinement\" in event.label:\n            print(f\"\\nRefining based on feedback...\")\n    elif isinstance(event, af.PhaseEnded):\n        print(f\" done ({event.elapsed_ms}ms)\")\n    elif hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\nrunner = af.Runner(\n    flow=review_loop_flow,\n    session=SQLiteSession(\"review.db\"),\n    handler=progress_handler,\n)\n</code></pre>"},{"location":"examples/review-loop/#best-practices","title":"Best Practices","text":"<ol> <li>Set max iterations \u2014 Prevent infinite loops</li> <li>Clear approval criteria \u2014 Make it unambiguous when to stop</li> <li>Accumulate context \u2014 Pass original request to refiner</li> <li>Persist only final \u2014 Use <code>persist=True</code> only on the last phase</li> <li>Use typed reviews \u2014 Structured output makes decisions clearer</li> </ol> <p>Back to: Home</p>"},{"location":"getting-started/first-flow/","title":"Your First Flow","text":"<p>This guide walks through building a flow step by step, explaining each concept as we go.</p>"},{"location":"getting-started/first-flow/#what-is-a-flow","title":"What is a Flow?","text":"<p>A Flow is just an async Python function that orchestrates agent calls:</p> <pre><code>async def my_flow(user_message: str) -&gt; str:\n    # Your agent orchestration logic here\n    return result\n</code></pre> <p>There's no special syntax or DSL. It's regular Python.</p>"},{"location":"getting-started/first-flow/#step-1-create-an-agent","title":"Step 1: Create an Agent","text":"<pre><code>import agentic_flow as af\n\nassistant = af.Agent(\n    name=\"assistant\",\n    instructions=\"You are a helpful assistant.\",\n    model=\"gpt-5.2\",\n)\n</code></pre> <p><code>Agent</code> is a thin wrapper around the OpenAI Agents SDK's <code>Agent</code>. All SDK arguments pass through unchanged.</p>"},{"location":"getting-started/first-flow/#step-2-call-the-agent","title":"Step 2: Call the Agent","text":"<pre><code># This creates an ExecutionSpec \u2014 NOT executed yet\nspec = assistant(\"Hello, how are you?\")\n</code></pre> <p>This is the Call-Spec discipline in action. Calling an agent returns a specification, not a result.</p>"},{"location":"getting-started/first-flow/#step-3-execute-with-await","title":"Step 3: Execute with await","text":"<pre><code># This executes the agent\nresult = await spec\n</code></pre> <p>Only <code>await</code> triggers execution. This makes it clear exactly where side effects occur.</p>"},{"location":"getting-started/first-flow/#step-4-add-modifiers","title":"Step 4: Add Modifiers","text":"<p>Modifiers configure execution behavior without triggering it:</p> <pre><code># Streaming mode\nresult = await assistant(\"Hello\").stream()\n\n# Silent mode (no UI output)\nresult = await assistant(\"Hello\").silent()\n\n# Isolated mode (no session context)\nresult = await assistant(\"Hello\").isolated()\n\n# Limit execution turns\nresult = await assistant(\"Hello\").max_turns(5)\n\n# Combine them (order doesn't matter)\nresult = await assistant(\"Hello\").stream().silent()\nresult = await assistant(\"Hello\").stream().max_turns(10)\n</code></pre>"},{"location":"getting-started/first-flow/#step-5-add-phases","title":"Step 5: Add Phases","text":"<p>Phases group related agent calls and manage boundaries:</p> <pre><code>import agentic_flow as af\n\nasync def my_flow(user_message: str) -&gt; str:\n    async with af.phase(\"Thinking\"):\n        thought = await assistant(\"Think about: \" + user_message).stream()\n\n    async with af.phase(\"Responding\", persist=True):\n        return await assistant(f\"Based on: {thought}, respond\").stream()\n</code></pre> <p>What <code>phase()</code> does:</p> <ul> <li>Creates a semantic boundary for UI display</li> <li>Manages a temporary context for agent calls within the phase</li> <li>Automatically cleans up when the phase ends</li> <li>With <code>persist=True</code>, saves the last exchange to the session</li> </ul>"},{"location":"getting-started/first-flow/#step-6-add-a-runner","title":"Step 6: Add a Runner","text":"<p>The Runner provides session management and executes the flow:</p> <pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\nrunner = af.Runner(\n    flow=my_flow,\n    session=SQLiteSession(\"chat.db\"),\n)\n\n# Execute\nresult = await runner(\"Hello!\")\n</code></pre>"},{"location":"getting-started/first-flow/#step-7-add-a-handler-optional","title":"Step 7: Add a Handler (Optional)","text":"<p>For CLI or custom output, add a handler:</p> <pre><code>def my_handler(event):\n    # Handle streaming events\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\nrunner = af.Runner(\n    flow=my_flow,\n    session=SQLiteSession(\"chat.db\"),\n    handler=my_handler,\n)\n</code></pre>"},{"location":"getting-started/first-flow/#complete-example","title":"Complete Example","text":"<pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\n# Agent\nassistant = af.Agent(\n    name=\"assistant\",\n    instructions=\"You are a thoughtful assistant.\",\n    model=\"gpt-5.2\",\n)\n\n# Flow\nasync def thoughtful_flow(user_message: str) -&gt; str:\n    # Internal thinking (not persisted)\n    async with af.phase(\"Thinking\"):\n        thought = await assistant(\n            f\"Think step by step about: {user_message}\"\n        ).stream()\n\n    # User-facing response (persisted)\n    async with af.phase(\"Response\", persist=True):\n        return await assistant(\n            f\"Based on your thinking:\\n{thought}\\n\\nProvide a clear response.\"\n        ).stream()\n\n# Handler for CLI output\ndef print_handler(event):\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\n# Runner\nrunner = af.Runner(\n    flow=thoughtful_flow,\n    session=SQLiteSession(\"chat.db\"),\n    handler=print_handler,\n)\n\n# Run\nif __name__ == \"__main__\":\n    result = runner.run_sync(\"Explain why the sky is blue.\")\n    print()  # Newline after streaming output\n</code></pre>"},{"location":"getting-started/first-flow/#summary","title":"Summary","text":"Concept Purpose <code>Agent</code> Wraps SDK Agent, makes it callable <code>agent(prompt)</code> Creates <code>ExecutionSpec</code> (no execution) <code>await spec</code> Executes the agent <code>.stream()</code> / <code>.silent()</code> / <code>.isolated()</code> Modifiers (no execution) <code>phase()</code> Semantic boundary with automatic cleanup <code>Runner</code> Executes flows with session injection <p>Next: Call-Spec Discipline </p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.12+</li> <li>uv (recommended) or pip</li> <li>OpenAI API key</li> </ul>"},{"location":"getting-started/installation/#install-with-uv-recommended","title":"Install with uv (recommended)","text":"<p>uv is a fast Python package manager that handles dependencies and virtual environments automatically.</p> <pre><code># Install uv if you don't have it\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Add AF to your project\nuv add ds-agentic-flow\n</code></pre>"},{"location":"getting-started/installation/#install-with-pip-alternative","title":"Install with pip (alternative)","text":"<pre><code>pip install ds-agentic-flow\n</code></pre> <p>This installs AF and its dependencies, including the OpenAI Agents SDK.</p>"},{"location":"getting-started/installation/#set-up-your-api-key","title":"Set up your API key","text":"<p>AF uses the OpenAI Agents SDK, which requires an API key:</p> <pre><code>export OPENAI_API_KEY=\"your-api-key\"\n</code></pre> <p>Or create a <code>.env</code> file:</p> <pre><code>OPENAI_API_KEY=your-api-key\n</code></pre> <p>And load it in your code:</p> <pre><code>from dotenv import load_dotenv\nload_dotenv()\n</code></pre>"},{"location":"getting-started/installation/#development-setup","title":"Development Setup","text":"<p>To contribute or run samples locally:</p> <pre><code># Clone the repository\ngit clone https://github.com/daiichisankyo/AgenticFlow.git\ncd AgenticFlow\n\n# Install with dev dependencies\nuv sync --group dev\n\n# Run tests\nuv run pytest\n\n# Run linter\nuv run ruff check src/\n\n# Build documentation\nuv sync --group docs\nuv run mkdocs serve\n</code></pre>"},{"location":"getting-started/installation/#project-structure","title":"Project Structure","text":"<pre><code>AgenticFlow/\n\u251c\u2500\u2500 pyproject.toml      # Package config + dependency groups\n\u251c\u2500\u2500 uv.lock             # Lock file\n\u251c\u2500\u2500 src/agentic_flow/   # Library source\n\u251c\u2500\u2500 tests/              # Test suite\n\u2514\u2500\u2500 sample/             # Sample applications\n</code></pre>"},{"location":"getting-started/installation/#dependency-groups","title":"Dependency Groups","text":"Group Purpose Command <code>dev</code> Testing, linting <code>uv sync --group dev</code> <code>docs</code> Documentation <code>uv sync --group docs</code> <code>sample</code> Sample apps <code>uv sync --group sample</code> <p>Run sample applications:</p> <pre><code>uv sync --group sample\nuv run python -m sample.guide.cli\n</code></pre>"},{"location":"getting-started/installation/#verify-installation","title":"Verify installation","text":"<pre><code>import agentic_flow as af\n\nassistant = af.Agent(\n    name=\"assistant\",\n    instructions=\"Say hello.\",\n    model=\"gpt-5.2\",\n)\n\nasync def greet(message: str) -&gt; str:\n    return await assistant(message)\n\nrunner = af.Runner(flow=greet)\nresult = runner.run_sync(\"Hi!\")\nprint(result)\n</code></pre> <p>If you see a greeting, you're ready to go.</p> <p>Next: Quickstart </p>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":"<p>Get a multi-agent workflow running in 5 minutes.</p>"},{"location":"getting-started/quickstart/#the-goal","title":"The Goal","text":"<p>We'll build a simple research-and-respond flow:</p> <ol> <li>A researcher agent gathers information</li> <li>A responder agent formulates a user-facing answer</li> </ol>"},{"location":"getting-started/quickstart/#step-1-define-agents","title":"Step 1: Define Agents","text":"<pre><code>import agentic_flow as af\n\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research the given topic. Provide detailed findings.\",\n    model=\"gpt-5.2\",\n)\n\nresponder = af.Agent(\n    name=\"responder\",\n    instructions=\"Based on research findings, provide a clear response to the user.\",\n    model=\"gpt-5.2\",\n)\n</code></pre> <p>Each <code>Agent</code> wraps the OpenAI Agents SDK. All SDK arguments (<code>model</code>, <code>instructions</code>, <code>tools</code>, etc.) pass through directly.</p>"},{"location":"getting-started/quickstart/#step-2-define-the-flow","title":"Step 2: Define the Flow","text":"<pre><code>import agentic_flow as af\n\nasync def research_flow(user_message: str) -&gt; str:\n    # Phase 1: Research (internal thinking, not saved to session)\n    async with af.phase(\"Research\"):\n        findings = await researcher(user_message).stream()\n\n    # Phase 2: Response (persist=True saves to session)\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Research findings:\\n{findings}\").stream()\n</code></pre> <p>Key points:</p> <ul> <li><code>phase()</code> creates a boundary \u2014 cleanup is automatic</li> <li><code>.stream()</code> enables streaming output</li> <li><code>persist=True</code> writes the final result to the session</li> </ul>"},{"location":"getting-started/quickstart/#step-3-run-with-a-runner","title":"Step 3: Run with a Runner","text":"<pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\nrunner = af.Runner(\n    flow=research_flow,\n    session=SQLiteSession(\"conversation.db\"),\n)\n\n# Async execution\nresult = await runner(\"What is quantum computing?\")\nprint(result)\n\n# Or synchronous (for scripts/Jupyter)\nresult = runner.run_sync(\"What is quantum computing?\")\nprint(result)\n</code></pre>"},{"location":"getting-started/quickstart/#full-example","title":"Full Example","text":"<pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\n# Define agents\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research the given topic. Provide detailed findings.\",\n    model=\"gpt-5.2\",\n)\n\nresponder = af.Agent(\n    name=\"responder\",\n    instructions=\"Based on research findings, provide a clear response to the user.\",\n    model=\"gpt-5.2\",\n)\n\n# Define flow\nasync def research_flow(user_message: str) -&gt; str:\n    # Internal thinking - not saved to session\n    async with af.phase(\"Research\"):\n        findings = await researcher(user_message).stream()\n\n    # persist=True saves the final response to session\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Research findings:\\n{findings}\").stream()\n\n# Run\nrunner = af.Runner(\n    flow=research_flow,\n    session=SQLiteSession(\"conversation.db\"),\n)\n\nresult = runner.run_sync(\"What is quantum computing?\")\nprint(result)\n</code></pre>"},{"location":"getting-started/quickstart/#what-just-happened","title":"What Just Happened?","text":"<ol> <li><code>researcher(user_message)</code> created an <code>ExecutionSpec</code> \u2014 no execution yet</li> <li><code>.stream()</code> added streaming mode \u2014 still no execution</li> <li><code>await</code> triggered the actual execution</li> <li><code>phase(\"Research\")</code> wrapped the execution with automatic boundary management</li> <li>The responder received the research findings and generated a response</li> <li><code>persist=True</code> saved the final exchange to the SQLite session</li> </ol>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Your First Flow \u2014 Deeper dive into flow structure</li> <li>Concepts \u2014 Understand Call-Spec discipline</li> <li>Streaming \u2014 Add real-time output</li> </ul> <p>Next: Your First Flow </p>"},{"location":"guides/chatkit/","title":"ChatKit Integration","text":"<p>ChatKit provides a web UI for agent conversations. AF integrates with ChatKit through <code>run_with_chatkit_context</code>.</p>"},{"location":"guides/chatkit/#overview","title":"Overview","text":"<pre><code>graph LR\n    A(ChatKitServer) --&gt; B(run_with_chatkit_context)\n    B --&gt; C(Runner + Flow)\n    C --&gt; D(Agents)\n    D --&gt; E(ChatKit UI)</code></pre>"},{"location":"guides/chatkit/#server-setup","title":"Server Setup","text":"<p>Create a <code>ChatKitServer</code> subclass:</p> <pre><code>import agentic_flow as af\nfrom agentic_flow.chatkit import run_with_chatkit_context\nfrom agents import SQLiteSession\nfrom chatkit.server import ChatKitServer\nfrom chatkit.types import ThreadMetadata, UserMessageItem\n\nfrom .flow import my_flow  # Your flow\n\n\nclass MyServer(ChatKitServer):\n    async def respond(\n        self,\n        thread: ThreadMetadata,\n        item: UserMessageItem | None,\n        context: dict,\n    ):\n        # Extract user message\n        user_message = \"\"\n        if item and item.content:\n            for part in item.content:\n                if hasattr(part, \"text\"):\n                    user_message += part.text\n\n        # Create session and runner\n        session = SQLiteSession(\n            session_id=thread.id,\n            db_path=\"data/sessions.db\",\n        )\n        runner = af.Runner(flow=my_flow, session=session)\n\n        # Execute with ChatKit context\n        async for event in run_with_chatkit_context(\n            runner, thread, self.store, context, user_message\n        ):\n            yield event\n</code></pre>"},{"location":"guides/chatkit/#fastapi-integration","title":"FastAPI Integration","text":"<pre><code>from fastapi import FastAPI, Request\nfrom fastapi.responses import Response, StreamingResponse\nfrom chatkit.server import StreamingResult\n\napp = FastAPI()\nserver = MyServer()\n\n\n@app.post(\"/chatkit\")\nasync def chatkit_endpoint(request: Request) -&gt; Response:\n    payload = await request.body()\n    result = await server.process(payload, {\"request\": request})\n\n    if isinstance(result, StreamingResult):\n        return StreamingResponse(result, media_type=\"text/event-stream\")\n    return Response(content=result.json, media_type=\"application/json\")\n</code></pre>"},{"location":"guides/chatkit/#phase-labels-in-chatkit","title":"Phase Labels in ChatKit","text":"<p>Each <code>phase()</code> creates a workflow boundary in ChatKit:</p> <pre><code>async def my_flow(message: str) -&gt; str:\n    async with af.phase(\"Research\"):      # \u2190 Creates workflow boundary\n        findings = await researcher(message).stream()\n\n    async with af.phase(\"Response\"):       # \u2190 Creates new workflow boundary\n        return await responder(findings).stream()\n</code></pre> <p>In the ChatKit UI:</p> <ul> <li>Each phase appears as a labeled section</li> <li>Reasoning steps display within their phase</li> <li>Phases are collapsible</li> </ul>"},{"location":"guides/chatkit/#workflow-boundaries","title":"Workflow Boundaries","text":"<p>ChatKit uses \"workflows\" to group reasoning display. AF manages these automatically:</p> <ol> <li><code>phase()</code> start \u2192 <code>emit_phase_label()</code> \u2192 saves message to store</li> <li>Agent execution \u2192 <code>stream_agent_response()</code> \u2192 creates workflow</li> <li><code>phase()</code> end \u2192 <code>close_workflow()</code> \u2192 ends workflow</li> </ol> <p>This ensures each phase gets independent reasoning display.</p>"},{"location":"guides/chatkit/#handler-vs-chatkit","title":"Handler vs ChatKit","text":"<p>When using <code>run_with_chatkit_context()</code>:</p> <ul> <li>Handler is NOT used \u2014 Events go to ChatKit's queue instead</li> <li>Phase events still emit \u2014 But to ChatKit, not handler</li> </ul> <p>For CLI output with ChatKit backend, you'd need a separate handler setup.</p>"},{"location":"guides/chatkit/#silent-mode-in-chatkit","title":"Silent Mode in ChatKit","text":"<p><code>.silent()</code> suppresses ChatKit UI display:</p> <pre><code>async with af.phase(\"Background\"):\n    # This output doesn't appear in ChatKit UI\n    result = await agent(task).stream().silent()\n</code></pre> <p>The agent runs normally, but events aren't pushed to the UI queue.</p>"},{"location":"guides/chatkit/#error-handling","title":"Error Handling","text":"<p><code>run_with_chatkit_context</code> handles errors gracefully:</p> <pre><code># Errors are caught and displayed in ChatKit\nasync for event in run_with_chatkit_context(...):\n    yield event\n# If an error occurs, an error message is added to the thread\n</code></pre>"},{"location":"guides/chatkit/#session-with-chatkit","title":"Session with ChatKit","text":"<p>Session ID typically maps to thread ID:</p> <pre><code>session = SQLiteSession(\n    session_id=thread.id,  # Use thread ID for session\n    db_path=\"data/sessions.db\",\n)\n</code></pre> <p>This ensures conversation history persists across page reloads.</p>"},{"location":"guides/chatkit/#complete-example","title":"Complete Example","text":"<pre><code>import agentic_flow as af\nfrom agentic_flow.chatkit import run_with_chatkit_context\nfrom agents import SQLiteSession\nfrom chatkit.server import ChatKitServer\nfrom chatkit.types import ThreadMetadata, UserMessageItem\nfrom fastapi import FastAPI, Request\nfrom fastapi.responses import Response, StreamingResponse\nfrom chatkit.server import StreamingResult\n\n# Agents\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research topics thoroughly.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\n\nresponder = af.Agent(\n    name=\"responder\",\n    instructions=\"Provide clear, helpful responses.\",\n    model=\"gpt-5.2\",\n)\n\n\n# Flow\nasync def research_flow(message: str) -&gt; str:\n    async with af.phase(\"Research\"):\n        findings = await researcher(message).stream()\n\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Based on: {findings}\").stream()\n\n\n# Server\nclass ResearchServer(ChatKitServer):\n    async def respond(self, thread: ThreadMetadata, item: UserMessageItem | None, context: dict):\n        user_message = \"\"\n        if item and item.content:\n            for part in item.content:\n                if hasattr(part, \"text\"):\n                    user_message += part.text\n\n        session = SQLiteSession(session_id=thread.id, db_path=\"data/sessions.db\")\n        runner = af.Runner(flow=research_flow, session=session)\n\n        async for event in run_with_chatkit_context(\n            runner, thread, self.store, context, user_message\n        ):\n            yield event\n\n\n# FastAPI app\napp = FastAPI()\nserver = ResearchServer()\n\n\n@app.post(\"/chatkit\")\nasync def chatkit_endpoint(request: Request) -&gt; Response:\n    payload = await request.body()\n    result = await server.process(payload, {\"request\": request})\n\n    if isinstance(result, StreamingResult):\n        return StreamingResponse(result, media_type=\"text/event-stream\")\n    return Response(content=result.json, media_type=\"application/json\")\n</code></pre> <p>Next: Structured Output </p>"},{"location":"guides/cli-patterns/","title":"CLI Display Patterns","text":"<p>Advanced patterns for building rich command-line interfaces with AF.</p>"},{"location":"guides/cli-patterns/#intent","title":"Intent","text":"<p>CLI applications need more than simple text output. This guide covers:</p> <ul> <li>Multi-panel layouts (reasoning, output, tools)</li> <li>Content-type aware rendering (text, markdown, JSON)</li> <li>Incremental JSON parsing for tool arguments</li> <li>Live updating displays</li> </ul>"},{"location":"guides/cli-patterns/#streamrenderer-pattern","title":"StreamRenderer Pattern","text":"<p>Buffer streaming content with content-type awareness:</p> <pre><code>import json\nfrom typing import Literal\n\nContentType = Literal[\"text\", \"markdown\", \"json\"]\n\nclass StreamRenderer:\n    \"\"\"Content-type aware stream renderer.\"\"\"\n\n    def __init__(self, content_type: ContentType = \"text\"):\n        self.buffer = \"\"\n        self.content_type = content_type\n        self.json_decoder = json.JSONDecoder()\n        self.last_valid_json = None\n\n    def clear(self):\n        \"\"\"Reset buffer state.\"\"\"\n        self.buffer = \"\"\n        self.last_valid_json = None\n\n    def append(self, delta: str):\n        \"\"\"Append delta and parse if JSON.\"\"\"\n        self.buffer += delta\n        if self.content_type == \"json\":\n            self.try_parse_json()\n\n    def try_parse_json(self):\n        \"\"\"Incremental JSON parsing with raw_decode.\n\n        Handles:\n        - Complete JSON objects\n        - Incomplete JSON (waits for more data)\n        - NDJSON (multiple objects)\n        \"\"\"\n        buf = self.buffer.strip()\n        if not buf:\n            return\n\n        try:\n            obj, _ = self.json_decoder.raw_decode(buf)\n            self.last_valid_json = obj\n        except json.JSONDecodeError:\n            pass  # Wait for more data\n\n    def render(self) -&gt; str:\n        \"\"\"Render based on content type.\"\"\"\n        if self.content_type == \"json\" and self.last_valid_json:\n            return json.dumps(self.last_valid_json, indent=2)\n        return self.buffer\n</code></pre>"},{"location":"guides/cli-patterns/#multi-panel-handler","title":"Multi-Panel Handler","text":"<p>Route events to separate display areas:</p> <pre><code>class MultiPanelHandler:\n    \"\"\"Handler with separate reasoning, output, and tool panels.\"\"\"\n\n    def __init__(self):\n        self.reasoning = StreamRenderer(\"text\")\n        self.output = StreamRenderer(\"text\")\n        self.tools: list[str] = []\n\n    def __call__(self, event):\n        import agentic_flow as af\n\n        # Phase boundaries\n        if isinstance(event, af.PhaseStarted):\n            self.on_phase_start(event.label)\n            return\n        if isinstance(event, af.PhaseEnded):\n            self.on_phase_end(event.label, event.elapsed_ms)\n            return\n\n        # SDK streaming events\n        if getattr(event, \"type\", None) != \"raw_response_event\":\n            return\n\n        data = getattr(event, \"data\", None)\n        if not data:\n            return\n\n        data_type = getattr(data, \"type\", \"\")\n        delta = getattr(data, \"delta\", \"\")\n\n        if data_type == \"response.reasoning_summary_text.delta\":\n            self.reasoning.append(delta)\n            self.refresh()\n        elif data_type == \"response.output_text.delta\":\n            self.output.append(delta)\n            self.refresh()\n        elif data_type == \"response.function_call_arguments.delta\":\n            self.output.append(delta)\n            self.refresh()\n        elif data_type == \"response.output_item.added\":\n            item = getattr(data, \"item\", None)\n            if item and getattr(item, \"type\", \"\") == \"function_call\":\n                tool_name = getattr(item, \"name\", \"tool\")\n                self.on_tool_start(tool_name)\n\n    def on_phase_start(self, label: str):\n        \"\"\"Clear buffers for new phase.\"\"\"\n        self.reasoning.clear()\n        self.output.clear()\n\n    def on_phase_end(self, label: str, elapsed_ms: int):\n        \"\"\"Phase completed.\"\"\"\n        pass\n\n    def on_tool_start(self, tool_name: str):\n        \"\"\"New tool call - switch output to JSON mode.\"\"\"\n        self.output.clear()\n        self.output.content_type = \"json\"\n        self.tools.append(tool_name)\n\n    def refresh(self):\n        \"\"\"Update display - implement with your UI library.\"\"\"\n        pass\n</code></pre>"},{"location":"guides/cli-patterns/#rich-library-integration","title":"Rich Library Integration","text":"<p>Using Rich for beautiful terminal output:</p> <pre><code>from rich.console import Console, Group\nfrom rich.live import Live\nfrom rich.panel import Panel\nfrom rich.json import JSON as RichJSON\nfrom rich.markdown import Markdown\nfrom rich.syntax import Syntax\nfrom rich.text import Text\n\nclass RichStreamRenderer:\n    \"\"\"Rich-aware stream renderer.\"\"\"\n\n    def __init__(self, content_type: ContentType = \"text\"):\n        self.buffer = \"\"\n        self.content_type = content_type\n        self.json_decoder = json.JSONDecoder()\n        self.last_valid_json = None\n\n    def render(self):\n        \"\"\"Render to Rich renderable.\"\"\"\n        if not self.buffer.strip():\n            return Text.from_markup(\"[dim]...[/dim]\")\n\n        if self.content_type == \"text\":\n            return Text(self.buffer)\n        elif self.content_type == \"markdown\":\n            return Markdown(self.buffer)\n        elif self.content_type == \"json\":\n            if self.last_valid_json is not None:\n                return RichJSON.from_data(self.last_valid_json)\n            return Syntax(self.buffer, \"json\", word_wrap=True)\n\n        return Text(self.buffer)\n\n\nclass RichDisplay:\n    \"\"\"Multi-panel Rich display.\"\"\"\n\n    def __init__(self, console: Console):\n        self.console = console\n        self.reasoning = RichStreamRenderer(\"text\")\n        self.output = RichStreamRenderer(\"text\")\n        self.live: Live | None = None\n\n    def start(self):\n        \"\"\"Start live display.\"\"\"\n        self.live = Live(self.build(), console=self.console, refresh_per_second=4)\n        self.live.start()\n\n    def stop(self):\n        \"\"\"Stop live display.\"\"\"\n        if self.live:\n            self.live.stop()\n            self.live = None\n\n    def update(self):\n        \"\"\"Refresh display.\"\"\"\n        if self.live:\n            self.live.update(self.build())\n\n    def build(self) -&gt; Group:\n        \"\"\"Build multi-panel layout.\"\"\"\n        panels = []\n\n        if self.reasoning.buffer.strip():\n            panels.append(Panel(\n                self.reasoning.render(),\n                title=\"[bold]Reasoning[/bold]\",\n                border_style=\"dim\",\n            ))\n\n        panels.append(Panel(\n            self.output.render(),\n            title=\"[bold]Output[/bold]\",\n            border_style=\"cyan\",\n        ))\n\n        return Group(*panels)\n</code></pre>"},{"location":"guides/cli-patterns/#complete-example","title":"Complete Example","text":"<pre><code>import agentic_flow as af\n\n# Agents\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research thoroughly.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\n\n# Rich display\nfrom rich.console import Console\n\nconsole = Console()\ndisplay = RichDisplay(console)\n\ndef rich_handler(event):\n    import agentic_flow as af\n\n    if isinstance(event, af.PhaseStarted):\n        display.reasoning.buffer = \"\"\n        display.output.buffer = \"\"\n        display.start()\n        return\n\n    if isinstance(event, af.PhaseEnded):\n        display.stop()\n        return\n\n    if getattr(event, \"type\", None) != \"raw_response_event\":\n        return\n\n    data = getattr(event, \"data\", None)\n    if not data:\n        return\n\n    data_type = getattr(data, \"type\", \"\")\n    delta = getattr(data, \"delta\", \"\")\n\n    if data_type == \"response.reasoning_summary_text.delta\":\n        display.reasoning.buffer += delta\n        display.update()\n    elif data_type == \"response.output_text.delta\":\n        display.output.buffer += delta\n        display.update()\n\n\nasync def research_flow(message: str) -&gt; str:\n    async with af.phase(\"Research\", persist=True):\n        return await researcher(message).stream()\n\n\nrunner = af.Runner(flow=research_flow, handler=rich_handler)\n\nif __name__ == \"__main__\":\n    result = runner.run_sync(\"Explain quantum computing\")\n    console.print(f\"\\n[green]Done![/green] {len(result)} chars\")\n</code></pre> <p>Next: Testing </p>"},{"location":"guides/streaming/","title":"Streaming","text":"<p>Streaming enables real-time output display. This guide covers CLI streaming with handlers.</p>"},{"location":"guides/streaming/#basic-streaming","title":"Basic Streaming","text":"<p>Add <code>.stream()</code> to enable streaming:</p> <pre><code>result = await assistant(\"Hello\").stream()\n</code></pre> <p>Without <code>.stream()</code>, you get only the final result. With <code>.stream()</code>, events are forwarded to your handler as they arrive.</p>"},{"location":"guides/streaming/#cli-handler","title":"CLI Handler","text":"<p>For command-line output, create a handler:</p> <pre><code>import agentic_flow as af\n\nassistant = af.Agent(name=\"assistant\", instructions=\"...\", model=\"gpt-5.2\")\n\ndef cli_handler(event):\n    # Text delta from streaming\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\nasync def my_flow(message: str) -&gt; str:\n    async with af.phase(\"Response\"):\n        return await assistant(message).stream()\n\nrunner = af.Runner(flow=my_flow, handler=cli_handler)\nresult = runner.run_sync(\"Hello!\")\nprint()  # Newline after streaming\n</code></pre>"},{"location":"guides/streaming/#handler-and-event-types","title":"Handler and Event Types","text":"<p>Your handler receives various event types:</p> <pre><code>import agentic_flow as af, af.AgentResult\n\ndef full_handler(event):\n    # Phase boundaries\n    if isinstance(event, af.PhaseStarted):\n        print(f\"\\n[{event.label}]\")\n        return\n\n    if isinstance(event, af.PhaseEnded):\n        print(f\"\\n[/{event.label}] ({event.elapsed_ms}ms)\")\n        return\n\n    # Non-streaming agent result\n    if isinstance(event, af.AgentResult):\n        print(event.content)\n        return\n\n    # Streaming text delta\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n</code></pre>"},{"location":"guides/streaming/#sdk-streamevent","title":"SDK StreamEvent","text":"<p>Most streaming events are SDK <code>StreamEvent</code> objects wrapped in <code>raw_response_event</code>. The <code>data.type</code> field identifies the specific event:</p> Event Type Description Key Attributes <code>response.output_text.delta</code> Text output chunk <code>data.delta</code> (str) <code>response.reasoning_summary_text.delta</code> Reasoning summary chunk <code>data.delta</code> (str) <code>response.function_call_arguments.delta</code> Tool arguments chunk <code>data.delta</code> (str, JSON fragment) <code>response.output_item.added</code> New output item started <code>data.item</code> (type, name) <pre><code>def inspect_handler(event):\n    # Check for raw_response_event wrapper\n    if getattr(event, \"type\", None) != \"raw_response_event\":\n        return\n\n    data = getattr(event, \"data\", None)\n    if not data:\n        return\n\n    data_type = getattr(data, \"type\", \"\")\n\n    # Text output\n    if data_type == \"response.output_text.delta\":\n        print(data.delta, end=\"\", flush=True)\n\n    # Reasoning (for separate display)\n    elif data_type == \"response.reasoning_summary_text.delta\":\n        print(f\"[Reasoning] {data.delta}\")\n\n    # Tool call arguments (JSON streaming)\n    elif data_type == \"response.function_call_arguments.delta\":\n        print(f\"[Tool Args] {data.delta}\")\n\n    # New tool call started\n    elif data_type == \"response.output_item.added\":\n        item = getattr(data, \"item\", None)\n        if item and getattr(item, \"type\", \"\") == \"function_call\":\n            print(f\"[Tool] {getattr(item, 'name', 'unknown')}\")\n</code></pre>"},{"location":"guides/streaming/#dual-panel-display","title":"Dual-Panel Display","text":"<p>For advanced CLI applications, separate reasoning from output:</p> <pre><code>class DualPanelHandler:\n    def __init__(self):\n        self.reasoning_buffer = \"\"\n        self.output_buffer = \"\"\n\n    def __call__(self, event):\n        if getattr(event, \"type\", None) != \"raw_response_event\":\n            return\n\n        data = getattr(event, \"data\", None)\n        if not data:\n            return\n\n        data_type = getattr(data, \"type\", \"\")\n        delta = getattr(data, \"delta\", \"\")\n\n        if data_type == \"response.reasoning_summary_text.delta\":\n            self.reasoning_buffer += delta\n            self.refresh_display()\n        elif data_type == \"response.output_text.delta\":\n            self.output_buffer += delta\n            self.refresh_display()\n\n    def refresh_display(self):\n        # Update your UI with separate panels\n        pass\n</code></pre> <p>This pattern enables:</p> <ul> <li>Reasoning Panel: Shows LLM thinking process</li> <li>Output Panel: Shows final response</li> <li>Tool Panel: Shows tool calls and arguments</li> </ul>"},{"location":"guides/streaming/#async-handlers","title":"Async Handlers","text":"<p>Handlers can be async:</p> <pre><code>async def async_handler(event):\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        await some_async_operation(event.data.delta)\n</code></pre> <p>AF detects async handlers and awaits them.</p>"},{"location":"guides/streaming/#streaming-without-handler","title":"Streaming Without Handler","text":"<p>If no handler is set, <code>.stream()</code> still works \u2014 it just doesn't output anywhere:</p> <pre><code># No handler \u2014 streaming happens internally but no display\nrunner = af.Runner(flow=my_flow)\nresult = await runner(\"Hello\")\n</code></pre> <p>The agent still runs in streaming mode, which may affect behavior (e.g., reasoning display).</p>"},{"location":"guides/streaming/#silent-streaming","title":"Silent Streaming","text":"<p>Combine <code>.silent()</code> with <code>.stream()</code> for internal streaming without display:</p> <pre><code>async with af.phase(\"Background\"):\n    # Streams internally but suppresses handler/UI output\n    result = await agent(\"task\").stream().silent()\n</code></pre>"},{"location":"guides/streaming/#reasoning-display","title":"Reasoning Display","text":"<p>With <code>ModelSettings</code> containing reasoning, streaming emits <code>response.reasoning_summary_text.delta</code> events:</p> <pre><code>import agentic_flow as af\n\nagent = af.Agent(\n    name=\"thinker\",\n    instructions=\"Think step by step.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),  # Helper for reasoning config\n)\n\n# Reasoning steps appear as separate event type\nresult = await agent(\"Complex problem\").stream()\n</code></pre> <p>To display reasoning separately from output:</p> <pre><code>def reasoning_aware_handler(event):\n    if getattr(event, \"type\", None) != \"raw_response_event\":\n        return\n\n    data = getattr(event, \"data\", None)\n    if not data:\n        return\n\n    data_type = getattr(data, \"type\", \"\")\n    delta = getattr(data, \"delta\", \"\")\n\n    if data_type == \"response.reasoning_summary_text.delta\":\n        # Display in reasoning panel (dimmed, separate area)\n        print(f\"\\033[2m{delta}\\033[0m\", end=\"\", flush=True)\n    elif data_type == \"response.output_text.delta\":\n        # Display in main output area\n        print(delta, end=\"\", flush=True)\n</code></pre>"},{"location":"guides/streaming/#complete-example","title":"Complete Example","text":"<pre><code>import agentic_flow as af, af.PhaseStarted, af.PhaseEnded\n\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research thoroughly.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"medium\"),\n)\n\nresponder = af.Agent(\n    name=\"responder\",\n    instructions=\"Provide clear responses.\",\n    model=\"gpt-5.2\",\n)\n\n\ndef cli_handler(event):\n    if isinstance(event, af.PhaseStarted):\n        print(f\"\\n--- {event.label} ---\")\n        return\n\n    if isinstance(event, af.PhaseEnded):\n        print(f\"\\n--- /{event.label} ({event.elapsed_ms}ms) ---\\n\")\n        return\n\n    if hasattr(event, \"data\") and hasattr(event.data, \"delta\"):\n        print(event.data.delta, end=\"\", flush=True)\n\n\nasync def research_flow(message: str) -&gt; str:\n    async with af.phase(\"Research\"):\n        findings = await researcher(message).stream()\n\n    async with af.phase(\"Response\", persist=True):\n        return await responder(f\"Based on: {findings}\").stream()\n\n\nrunner = af.Runner(flow=research_flow, handler=cli_handler)\n\nif __name__ == \"__main__\":\n    result = runner.run_sync(\"Explain quantum entanglement\")\n    print(f\"\\nFinal: {result[:100]}...\")\n</code></pre> <p> Next: CLI Display Patterns for advanced Rich/terminal UI</p> <p> Or: ChatKit Integration for web UI</p>"},{"location":"guides/structured-output/","title":"Structured Output","text":"<p>AF supports typed outputs using Pydantic models, enabling IDE completion and type checking.</p>"},{"location":"guides/structured-output/#basic-typed-output","title":"Basic Typed Output","text":"<p>Define a Pydantic model and pass it to <code>output_type</code>:</p> <pre><code>from pydantic import BaseModel\nimport agentic_flow as af\n\nclass Analysis(BaseModel):\n    sentiment: str\n    confidence: float\n    keywords: list[str]\n\nanalyzer = af.Agent(\n    name=\"analyzer\",\n    instructions=\"Analyze the sentiment of the given text.\",\n    model=\"gpt-5.2\",\n    output_type=Analysis,  # Typed output\n)\n\nresult: Analysis = await analyzer(\"I love this product!\")\nprint(result.sentiment)     # \"positive\"\nprint(result.confidence)    # 0.95\nprint(result.keywords)      # [\"love\", \"product\"]\n</code></pre>"},{"location":"guides/structured-output/#type-parameter","title":"Type Parameter","text":"<p><code>af.Agent[T]</code> is generic. <code>T</code> is determined by <code>output_type</code>:</p> <pre><code># T = str (default)\nassistant: af.Agent[str] = af.Agent(name=\"assistant\", instructions=\"...\", model=\"gpt-5.2\")\n\n# T = Analysis\nanalyzer: af.Agent[Analysis] = af.Agent(\n    name=\"analyzer\",\n    instructions=\"...\",\n    output_type=Analysis,\n    model=\"gpt-5.2\",\n)\n</code></pre> <p><code>ExecutionSpec[T]</code> carries the same type:</p> <pre><code>spec: ExecutionSpec[Analysis] = analyzer(\"text\")\nresult: Analysis = await spec\n</code></pre>"},{"location":"guides/structured-output/#nested-models","title":"Nested Models","text":"<p>Complex structures work as expected:</p> <pre><code>class Citation(BaseModel):\n    source: str\n    url: str\n    relevance: float\n\nclass ResearchResult(BaseModel):\n    summary: str\n    key_findings: list[str]\n    citations: list[Citation]\n    confidence: float\n\nresearcher = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research the topic and provide structured findings.\",\n    output_type=ResearchResult,\n    model=\"gpt-5.2\",\n)\n\nresult: ResearchResult = await researcher(\"quantum computing\").stream()\nfor citation in result.citations:\n    print(f\"{citation.source}: {citation.url}\")\n</code></pre>"},{"location":"guides/structured-output/#enum-fields","title":"Enum Fields","text":"<p>Use enums for constrained values:</p> <pre><code>from enum import Enum\n\nclass Sentiment(str, Enum):\n    POSITIVE = \"positive\"\n    NEGATIVE = \"negative\"\n    NEUTRAL = \"neutral\"\n\nclass SentimentAnalysis(BaseModel):\n    sentiment: Sentiment\n    confidence: float\n\nanalyzer = af.Agent(\n    name=\"analyzer\",\n    instructions=\"Classify sentiment.\",\n    output_type=SentimentAnalysis,\n    model=\"gpt-5.2\",\n)\n\nresult = await analyzer(\"Great product!\")\nif result.sentiment == Sentiment.POSITIVE:\n    print(\"User is happy!\")\n</code></pre>"},{"location":"guides/structured-output/#optional-fields","title":"Optional Fields","text":"<p>Handle optional data:</p> <pre><code>class UserProfile(BaseModel):\n    name: str\n    email: str | None = None\n    age: int | None = None\n\nextractor = af.Agent(\n    name=\"extractor\",\n    instructions=\"Extract user information from text.\",\n    output_type=UserProfile,\n    model=\"gpt-5.2\",\n)\n\nresult = await extractor(\"My name is Alice, I'm 30.\")\nprint(result.name)   # \"Alice\"\nprint(result.email)  # None\nprint(result.age)    # 30\n</code></pre>"},{"location":"guides/structured-output/#chaining-typed-agents","title":"Chaining Typed Agents","text":"<p>Pass structured output between agents:</p> <pre><code>class Triage(BaseModel):\n    category: str\n    priority: int\n    reason: str\n\nclass Response(BaseModel):\n    message: str\n    action_items: list[str]\n\ntriager = af.Agent(\n    name=\"triager\",\n    instructions=\"Categorize and prioritize the request.\",\n    output_type=Triage,\n    model=\"gpt-5.2\",\n)\n\nresponder = af.Agent(\n    name=\"responder\",\n    instructions=\"Respond based on the triage.\",\n    output_type=Response,\n    model=\"gpt-5.2\",\n)\n\nasync def support_flow(message: str) -&gt; str:\n    async with af.phase(\"Triage\"):\n        triage: Triage = await triager(message).stream()\n\n    async with af.phase(\"Response\", persist=True):\n        response: Response = await responder(\n            f\"Category: {triage.category}\\n\"\n            f\"Priority: {triage.priority}\\n\"\n            f\"Reason: {triage.reason}\\n\"\n            f\"Original: {message}\"\n        ).stream()\n\n    return response.message\n</code></pre>"},{"location":"guides/structured-output/#validation","title":"Validation","text":"<p>Pydantic validates output automatically:</p> <pre><code>class StrictAnalysis(BaseModel):\n    score: int  # Must be integer\n    category: str  # Required\n\n# If the model returns invalid data, Pydantic raises ValidationError\n</code></pre>"},{"location":"guides/structured-output/#streaming-with-typed-output","title":"Streaming with Typed Output","text":"<p>Streaming works with typed output \u2014 you get the final parsed result:</p> <pre><code>result: Analysis = await analyzer(\"text\").stream()\n# result is Analysis, not str\n</code></pre>"},{"location":"guides/structured-output/#sdk-pass-through","title":"SDK Pass-Through","text":"<p><code>output_type</code> is passed directly to the SDK:</p> <pre><code># AF\naf.Agent(name=\"...\", instructions=\"...\", output_type=MyModel, model=\"gpt-5.2\")\n\n# Equivalent SDK call\nagents.Agent(name=\"...\", instructions=\"...\", output_type=MyModel)\n</code></pre> <p>AF doesn't modify or wrap the SDK's structured output handling.</p> <p>Next: Testing </p>"},{"location":"guides/testing/","title":"Testing","text":"<p>Testing AF applications involves async tests and proper event loop handling.</p>"},{"location":"guides/testing/#pytest-asyncio-setup","title":"pytest-asyncio Setup","text":"<p>Install pytest-asyncio:</p> <pre><code>pip install pytest-asyncio\n</code></pre> <p>Configure in <code>pyproject.toml</code>:</p> <pre><code>[tool.pytest.ini_options]\nasyncio_mode = \"auto\"\nasyncio_default_fixture_loop_scope = \"function\"\n</code></pre>"},{"location":"guides/testing/#basic-test","title":"Basic Test","text":"<pre><code>import pytest\nimport agentic_flow as af\n\nassistant = af.Agent(name=\"assistant\", instructions=\"Say hello.\", model=\"gpt-5.2\")\n\nasync def greet_flow(message: str) -&gt; str:\n    async with af.phase(\"Greeting\"):\n        return await assistant(message)\n\n@pytest.mark.asyncio\nasync def test_greet_flow():\n    runner = af.Runner(flow=greet_flow)\n    result = await runner(\"Hi\")\n    assert \"hello\" in result.lower()\n</code></pre>"},{"location":"guides/testing/#event-loop-issue","title":"Event Loop Issue","text":"<p>pytest-asyncio creates a new event loop for each test. The OpenAI SDK caches a global HTTP client, which can cause issues:</p> <pre><code>RuntimeError: Event loop is closed\n</code></pre>"},{"location":"guides/testing/#solution-reset-http-client","title":"Solution: Reset HTTP Client","text":"<p>Create a fixture that resets the SDK's HTTP client:</p> <pre><code>import pytest\n\n@pytest.fixture(autouse=True)\ndef reset_openai_http_client():\n    \"\"\"Reset OpenAI SDK's cached HTTP client after each test.\"\"\"\n    yield\n    try:\n        import openai\n        if hasattr(openai, \"_base_client\") and openai._base_client is not None:\n            openai._base_client = None\n        if hasattr(openai, \"AsyncOpenAI\"):\n            # Reset any cached async clients\n            pass\n    except Exception:\n        pass\n</code></pre>"},{"location":"guides/testing/#testing-with-sessions","title":"Testing with Sessions","text":"<p>Use in-memory or temporary sessions:</p> <pre><code>import tempfile\nfrom agents import SQLiteSession\n\n@pytest.fixture\ndef session():\n    with tempfile.NamedTemporaryFile(suffix=\".db\") as f:\n        yield SQLiteSession(session_id=\"test\", db_path=f.name)\n\n@pytest.mark.asyncio\nasync def test_with_session(session):\n    runner = af.Runner(flow=my_flow, session=session)\n    result = await runner(\"Hello\")\n    assert result\n</code></pre>"},{"location":"guides/testing/#testing-phases","title":"Testing Phases","text":"<p>Verify phase behavior:</p> <pre><code>@pytest.mark.asyncio\nasync def test_phase_persist():\n    results = []\n\n    async def tracking_flow(message: str) -&gt; str:\n        async with af.phase(\"Work\", persist=True):\n            result = await assistant(message)\n            results.append(result)\n            return result\n\n    runner = af.Runner(flow=tracking_flow)\n    await runner(\"Test\")\n\n    assert len(results) == 1\n</code></pre>"},{"location":"guides/testing/#testing-handlers","title":"Testing Handlers","text":"<p>Capture events with a test handler:</p> <pre><code>import agentic_flow as af\n\n@pytest.mark.asyncio\nasync def test_handler_receives_events():\n    events = []\n\n    def test_handler(event):\n        events.append(event)\n\n    runner = af.Runner(flow=my_flow, handler=test_handler)\n    await runner(\"Hello\")\n\n    # Check phase events were received\n    phase_starts = [e for e in events if isinstance(e, af.PhaseStarted)]\n    phase_ends = [e for e in events if isinstance(e, af.PhaseEnded)]\n\n    assert len(phase_starts) &gt; 0\n    assert len(phase_starts) == len(phase_ends)\n</code></pre>"},{"location":"guides/testing/#testing-isolation","title":"Testing Isolation","text":"<p>Verify <code>.isolated()</code> works:</p> <pre><code>@pytest.mark.asyncio\nasync def test_isolated_no_session():\n    session_accessed = False\n\n    class TrackingSession:\n        async def get_items(self):\n            nonlocal session_accessed\n            session_accessed = True\n            return []\n\n    runner = af.Runner(flow=my_flow, session=TrackingSession())\n\n    # Isolated call shouldn't access session\n    result = await assistant(\"Hello\").isolated()\n\n    # Note: This tests the agent directly, not through the flow\n    assert not session_accessed\n</code></pre>"},{"location":"guides/testing/#parallel-test-execution","title":"Parallel Test Execution","text":"<p>When running tests in parallel, ensure isolation:</p> <pre><code>@pytest.mark.asyncio\nasync def test_parallel_agents():\n    import asyncio\n\n    results = await asyncio.gather(\n        agent(\"task 1\").isolated(),\n        agent(\"task 2\").isolated(),\n        agent(\"task 3\").isolated(),\n    )\n\n    assert len(results) == 3\n</code></pre>"},{"location":"guides/testing/#mocking-agents","title":"Mocking Agents","text":"<p>For unit tests without API calls, you can mock at the SDK level:</p> <pre><code>from unittest.mock import AsyncMock, patch\n\n@pytest.mark.asyncio\nasync def test_flow_logic_only():\n    with patch(\"agents.Runner.run\") as mock_run:\n        mock_run.return_value = AsyncMock(final_output=\"mocked response\")\n\n        runner = af.Runner(flow=my_flow)\n        result = await runner(\"Test\")\n\n        assert result == \"mocked response\"\n</code></pre>"},{"location":"guides/testing/#integration-tests","title":"Integration Tests","text":"<p>For full integration tests, use real API calls:</p> <pre><code>import os\nimport pytest\n\n@pytest.mark.skipif(\n    not os.getenv(\"OPENAI_API_KEY\"),\n    reason=\"OPENAI_API_KEY not set\"\n)\n@pytest.mark.asyncio\nasync def test_real_api():\n    runner = af.Runner(flow=my_flow)\n    result = await runner(\"What is 2+2?\")\n    assert \"4\" in result\n</code></pre>"},{"location":"guides/testing/#test-organization","title":"Test Organization","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py           # Fixtures (reset_openai_http_client)\n\u251c\u2500\u2500 test_flows.py         # Flow tests\n\u251c\u2500\u2500 test_agents.py        # Agent tests\n\u251c\u2500\u2500 test_phases.py        # Phase tests\n\u2514\u2500\u2500 test_integration.py   # Full integration tests\n</code></pre> <p>Next: API Reference </p>"},{"location":"reference/api/","title":"API Reference","text":"<p>Complete API documentation for AF.</p>"},{"location":"reference/api/#agent","title":"Agent","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#agentt","title":"Agent[T]","text":"<p>Wrapper around SDK Agent that enables callable form.</p> <pre><code>class af.Agent(Generic[T]):\n    def __init__(\n        self,\n        *,\n        output_type: type[T] | None = None,\n        **sdk_kwargs: Any,\n    ) -&gt; None: ...\n\n    def __call__(self, input: str) -&gt; af.ExecutionSpec[T]: ...\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>output_type</code> <code>type[T] \\| None</code> Pydantic model for typed output. If <code>None</code>, <code>T = str</code>. <code>**sdk_kwargs</code> <code>Any</code> All arguments passed to <code>agents.Agent</code> <p>Common sdk_kwargs:</p> Argument Type Description <code>name</code> <code>str</code> Agent name (required) <code>instructions</code> <code>str</code> System instructions <code>model</code> <code>str</code> Model name (e.g., <code>\"gpt-5.2\"</code>) <code>model_settings</code> <code>ModelSettings</code> Model configuration <code>tools</code> <code>list</code> Tool functions <code>handoffs</code> <code>list</code> Handoff agents <p>Example:</p> <pre><code>import agentic_flow as af\nfrom pydantic import BaseModel\n\nclass Analysis(BaseModel):\n    sentiment: str\n    score: float\n\n# str output\nassistant = af.Agent(name=\"assistant\", instructions=\"...\", model=\"gpt-5.2\")\n\n# Typed output\nanalyzer = af.Agent(name=\"analyzer\", instructions=\"...\", output_type=Analysis, model=\"gpt-5.2\")\n</code></pre>"},{"location":"reference/api/#executionspec","title":"ExecutionSpec","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#executionspect","title":"ExecutionSpec[T]","text":"<p>Awaitable execution specification. Created by <code>agent(prompt)</code>.</p> <pre><code>@dataclass\nclass ExecutionSpec(Generic[T]):\n    sdk_agent: SDKAgent\n    input: str = \"\"\n    streaming: bool = False\n    is_isolated: bool = False\n    is_silent: bool = False\n    max_turns_sdk: int | None = None\n    run_kwargs: dict[str, Any] = field(default_factory=dict)\n\n    # WHERE axis\n    def isolated(self) -&gt; ExecutionSpec[T]: ...\n\n    # HOW axis\n    def stream(self) -&gt; ExecutionSpec[T]: ...\n    def silent(self) -&gt; ExecutionSpec[T]: ...\n\n    # LIMITS axis\n    def max_turns(self, max_turns: int) -&gt; ExecutionSpec[T]: ...\n\n    # SDK pass-through\n    def run_config(self, run_config: RunConfig) -&gt; ExecutionSpec[T]: ...\n    def context(self, context: Any) -&gt; ExecutionSpec[T]: ...\n    def run_kwarg(self, **kwargs: Any) -&gt; ExecutionSpec[T]: ...\n\n    def __await__(self): ...\n</code></pre> <p>Methods:</p> Method Returns Axis Description <code>isolated()</code> <code>ExecutionSpec[T]</code> WHERE Execute without context <code>stream()</code> <code>ExecutionSpec[T]</code> HOW Enable streaming mode <code>silent()</code> <code>ExecutionSpec[T]</code> HOW Suppress UI display <code>max_turns(n)</code> <code>ExecutionSpec[T]</code> LIMITS Limit execution turns <code>run_config(cfg)</code> <code>ExecutionSpec[T]</code> SDK Set RunConfig <code>context(ctx)</code> <code>ExecutionSpec[T]</code> SDK Inject context (DI) <code>run_kwarg(**kw)</code> <code>ExecutionSpec[T]</code> SDK Set arbitrary SDK params <code>__await__</code> <code>T</code> - Execute and return result <p>Example:</p> <pre><code>spec = assistant(\"Hello\")           # ExecutionSpec[str]\nspec = spec.stream()                # ExecutionSpec[str] with streaming\nresult = await spec                 # str\n\n# With SDK pass-through\nresult = await agent(\"task\") \\\n    .max_turns(5) \\\n    .context(app_ctx) \\\n    .stream()\n</code></pre>"},{"location":"reference/api/#runner","title":"Runner","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#runner_1","title":"Runner","text":"<p>Flow execution container with session and handler injection.</p> <pre><code>class Runner:\n    def __init__(\n        self,\n        flow: Callable[[str], Awaitable[T]],\n        session: Session | None = None,\n        handler: af.Handler | None = None,\n    ) -&gt; None: ...\n\n    async def __call__(self, user_message: str) -&gt; T: ...\n    def run(self, user_message: str) -&gt; af.RunHandle: ...\n    def run_sync(self, user_message: str) -&gt; T: ...\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>flow</code> <code>Callable[[str], Awaitable[T]]</code> Async function to execute <code>session</code> <code>Session \\| None</code> SDK Session for history <code>handler</code> <code>Handler \\| None</code> Event handler <p>Methods:</p> Method Returns Description <code>__call__(msg)</code> <code>T</code> Execute flow (async) <code>run(msg)</code> <code>RunHandle</code> Create deferred handle <code>run_sync(msg)</code> <code>T</code> Execute synchronously <p>Example:</p> <pre><code>import agentic_flow as af\nfrom agents import SQLiteSession\n\nrunner = af.Runner(\n    flow=my_flow,\n    session=SQLiteSession(\"chat.db\"),\n    handler=my_handler,\n)\n\n# Async\nresult = await runner(\"Hello\")\n\n# Sync\nresult = runner.run_sync(\"Hello\")\n\n# Deferred\nresult = runner.run(\"Hello\").sync()\n</code></pre>"},{"location":"reference/api/#runhandle","title":"RunHandle","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#runhandle_1","title":"RunHandle","text":"<p>Deferred execution handle for synchronous contexts.</p> <pre><code>class RunHandle:\n    def sync(self) -&gt; T: ...\n    def __await__(self): ...\n</code></pre> <p>Methods:</p> Method Returns Description <code>sync()</code> <code>T</code> Execute synchronously <code>__await__</code> <code>T</code> Execute asynchronously"},{"location":"reference/api/#phase","title":"phase","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#phase_1","title":"phase()","text":"<p>Context manager for workflow phases.</p> <pre><code>@asynccontextmanager\nasync def phase(\n    label: str,\n    share_context: bool = True,\n    persist: bool = False,\n) -&gt; AsyncIterator[PhaseSession | None]: ...\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>label</code> <code>str</code> (required) Phase display name <code>share_context</code> <code>bool</code> <code>True</code> Create PhaseSession <code>persist</code> <code>bool</code> <code>False</code> Write to Session at end <p>Example:</p> <pre><code>async with af.phase(\"Research\"):\n    result = await agent(query).stream()\n\nasync with af.phase(\"Response\", persist=True):\n    return await agent(result).stream()\n</code></pre>"},{"location":"reference/api/#phasesession","title":"PhaseSession","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#phasesession_1","title":"PhaseSession","text":"<p>SessionABC-compliant session for phase execution.</p> <pre><code>class PhaseSession(SessionABC):\n    session_id: str\n    label: str\n    data: dict\n    inherited_history: list[TResponseInputItem]\n    items: list[TResponseInputItem]\n\n    async def get_items(self, limit: int | None = None) -&gt; list[TResponseInputItem]: ...\n    async def add_items(self, items: list[TResponseInputItem]) -&gt; None: ...\n    async def pop_item(self) -&gt; TResponseInputItem | None: ...\n    async def clear_session(self) -&gt; None: ...\n</code></pre> <p>Attributes:</p> Attribute Type Description <code>label</code> <code>str</code> Phase label <code>inherited_history</code> <code>list</code> Session history at phase start (read-only) <code>items</code> <code>list</code> Messages within phase (SDK-managed) <code>data</code> <code>dict</code> Custom data storage <p>Methods:</p> Method Returns Description <code>get_items(limit)</code> <code>list</code> <code>inherited_history + items</code> (async) <code>add_items(items)</code> <code>None</code> Add items to <code>items</code> (called by SDK) <code>pop_item()</code> <code>item \\| None</code> Pop from <code>items</code> <code>clear_session()</code> <code>None</code> Clear <code>items</code> <p>Example:</p> <pre><code>async with af.phase(\"Research\") as ctx:\n    await agent(query).stream()\n    ctx.my_note = \"important\"\n    print(ctx.my_note)\n</code></pre>"},{"location":"reference/api/#event-types","title":"Event Types","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#event","title":"Event","text":"<p>Union type for all events:</p> <pre><code>Event = Union[StreamEvent, PhaseStarted, PhaseEnded, AgentResult]\n</code></pre>"},{"location":"reference/api/#phasestarted","title":"PhaseStarted","text":"<pre><code>@dataclass(frozen=True)\nclass PhaseStarted:\n    type: Literal[\"phase.started\"]\n    label: str\n    ts: float\n</code></pre>"},{"location":"reference/api/#phaseended","title":"PhaseEnded","text":"<pre><code>@dataclass(frozen=True)\nclass PhaseEnded:\n    type: Literal[\"phase.ended\"]\n    label: str\n    elapsed_ms: int\n    ts: float\n</code></pre>"},{"location":"reference/api/#agentresult","title":"AgentResult","text":"<pre><code>@dataclass(frozen=True)\nclass AgentResult:\n    type: Literal[\"agent.result\"]\n    content: Any\n    ts: float\n</code></pre>"},{"location":"reference/api/#handler","title":"Handler","text":"<pre><code>Handler = Callable[[Event], Any]\n</code></pre>"},{"location":"reference/api/#sdk-streamevent-types","title":"SDK StreamEvent Types","text":"<p>AF forwards SDK streaming events wrapped in <code>raw_response_event</code>. Access via <code>event.data.type</code>:</p> Event Type Description Attributes <code>response.output_text.delta</code> Text output chunk <code>delta: str</code> <code>response.reasoning_summary_text.delta</code> Reasoning summary chunk <code>delta: str</code> <code>response.function_call_arguments.delta</code> Tool arguments (JSON) <code>delta: str</code> <code>response.output_item.added</code> New output item <code>item: {type, name}</code> <code>response.output_item.done</code> Output item complete <code>item: {...}</code> <p>Example: Event Routing</p> <pre><code>def handler(event):\n    if getattr(event, \"type\", None) != \"raw_response_event\":\n        # Handle AF events (af.PhaseStarted, af.PhaseEnded, etc.)\n        return\n\n    data = getattr(event, \"data\", None)\n    if not data:\n        return\n\n    match getattr(data, \"type\", \"\"):\n        case \"response.output_text.delta\":\n            # Main text output\n            pass\n        case \"response.reasoning_summary_text.delta\":\n            # Reasoning (separate display recommended)\n            pass\n        case \"response.function_call_arguments.delta\":\n            # Tool call arguments (JSON fragments)\n            pass\n        case \"response.output_item.added\":\n            # New tool call started\n            item = getattr(data, \"item\", None)\n            if item and getattr(item, \"type\", \"\") == \"function_call\":\n                tool_name = getattr(item, \"name\", \"\")\n</code></pre>"},{"location":"reference/api/#utilities","title":"Utilities","text":"<pre><code>import agentic_flow as af\n</code></pre>"},{"location":"reference/api/#reasoning","title":"reasoning()","text":"<p>Create ModelSettings with reasoning enabled.</p> <pre><code>def reasoning(\n    effort: Literal[\"low\", \"medium\", \"high\"] = \"medium\",\n    summary: Literal[\"auto\", \"concise\", \"detailed\"] = \"auto\",\n    **model_settings_kwargs: Any,\n) -&gt; ModelSettings: ...\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>effort</code> <code>str</code> <code>\"medium\"</code> Reasoning effort level <code>summary</code> <code>str</code> <code>\"auto\"</code> Summary style <code>**kwargs</code> <code>Any</code> Additional ModelSettings args <p>Example:</p> <pre><code>import agentic_flow as af\n\nagent = af.Agent(\n    name=\"thinker\",\n    instructions=\"Think step by step.\",\n    model=\"gpt-5.2\",\n    model_settings=af.reasoning(\"high\"),\n)\n</code></pre>"},{"location":"reference/api/#chatkit-integration","title":"ChatKit Integration","text":"<pre><code>from agentic_flow.chatkit import run_with_chatkit_context\n</code></pre>"},{"location":"reference/api/#run_with_chatkit_context","title":"run_with_chatkit_context()","text":"<p>Execute Runner with ChatKit context.</p> <pre><code>async def run_with_chatkit_context(\n    runner: Runner,\n    thread: ThreadMetadata,\n    store: Store,\n    context: dict[str, Any],\n    user_message: str,\n) -&gt; AsyncIterator[ThreadStreamEvent]: ...\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>runner</code> <code>Runner</code> Runner instance <code>thread</code> <code>ThreadMetadata</code> ChatKit thread <code>store</code> <code>Store</code> ChatKit store <code>context</code> <code>dict</code> Request context <code>user_message</code> <code>str</code> User message <p>Yields: <code>ThreadStreamEvent</code></p>"},{"location":"reference/api/#public-exports","title":"Public Exports","text":"<pre><code>import agentic_flow as af\n\n# Available exports:\n# af.Agent, af.ExecutionSpec, af.Runner, af.RunHandle, af.phase,\n# af.PhaseSession, af.Handler, af.Event, af.PhaseStarted,\n# af.PhaseEnded, af.AgentResult, af.reasoning\n</code></pre>"},{"location":"reference/sdk-compatibility/","title":"SDK Compatibility","text":"<p>AF is built on top of the OpenAI Agents SDK. This page documents the relationship and boundaries.</p>"},{"location":"reference/sdk-compatibility/#design-principle","title":"Design Principle","text":"<p>AF does not reinvent the SDK. It adds:</p> <ul> <li>Callable form for agents (<code>agent(prompt)</code>)</li> <li>Execution modifiers (<code>.stream()</code>, <code>.silent()</code>, <code>.isolated()</code>)</li> <li>Automatic boundary management (<code>phase()</code>)</li> <li>Session injection via Runner</li> </ul> <p>Everything else comes from the SDK.</p>"},{"location":"reference/sdk-compatibility/#sdk-pass-through","title":"SDK Pass-Through","text":"<p>All Agent arguments pass directly to the SDK:</p> <pre><code># AF\nimport agentic_flow as af\n\nagent = af.Agent(\n    name=\"assistant\",\n    instructions=\"Help the user.\",\n    model=\"gpt-5.2\",\n    model_settings=ModelSettings(reasoning=Reasoning(effort=\"medium\")),\n    tools=[my_tool],\n)\n\n# Internally creates:\nfrom agents import Agent as SDKAgent\n\nsdk_agent = SDKAgent(\n    name=\"assistant\",\n    instructions=\"Help the user.\",\n    model=\"gpt-5.2\",\n    model_settings=ModelSettings(reasoning=Reasoning(effort=\"medium\")),\n    tools=[my_tool],\n)\n</code></pre> <p>This means:</p> <ul> <li>Future SDK arguments work automatically</li> <li>No need for AF updates when SDK changes</li> <li>No aliasing or normalization of arguments</li> </ul>"},{"location":"reference/sdk-compatibility/#what-comes-from-sdk","title":"What Comes From SDK","text":"Feature SDK Class Usage in AF Agent definition <code>agents.Agent</code> Wrapped by <code>Agent</code> Execution <code>agents.Runner</code> Called by <code>ExecutionSpec</code> Streaming <code>agents.Runner.run_streamed</code> Used when <code>.stream()</code> Session <code>agents.Session</code> Injected by Runner SQLiteSession <code>agents.SQLiteSession</code> Passed to Runner StreamEvent <code>agents.StreamEvent</code> Forwarded to Handler ModelSettings <code>agents.ModelSettings</code> Passed through"},{"location":"reference/sdk-compatibility/#what-af-adds","title":"What AF Adds","text":"Feature Purpose <code>Agent[T]</code> Callable wrapper, <code>agent(prompt) \u2192 ExecutionSpec[T]</code> <code>ExecutionSpec[T]</code> Declaration/execution separation <code>phase()</code> Automatic boundary management <code>Runner</code> Flow execution with injection <code>.stream()</code> Streaming mode modifier <code>.silent()</code> Display suppression modifier <code>.isolated()</code> Context isolation modifier"},{"location":"reference/sdk-compatibility/#session-compatibility","title":"Session Compatibility","text":"<p>AF uses SDK Session directly:</p> <pre><code>from agents import SQLiteSession\n\nsession = SQLiteSession(session_id=\"user_123\", db_path=\"chat.db\")\nrunner = af.Runner(flow=my_flow, session=session)\n</code></pre> <p>Session methods used:</p> <ul> <li><code>get_items()</code> \u2014 Read history (by phase for inheritance)</li> <li><code>add_items()</code> \u2014 Write history (by phase with <code>persist=True</code>)</li> </ul>"},{"location":"reference/sdk-compatibility/#streamevent-handling","title":"StreamEvent Handling","text":"<p>SDK StreamEvents are forwarded unchanged via <code>raw_response_event</code>:</p> <pre><code>def my_handler(event):\n    # AF events\n    if isinstance(event, (af.PhaseStarted, af.PhaseEnded, af.AgentResult)):\n        return\n\n    # SDK events wrapped in raw_response_event\n    if getattr(event, \"type\", None) == \"raw_response_event\":\n        data = getattr(event, \"data\", None)\n        data_type = getattr(data, \"type\", \"\")\n\n        # Route by event type\n        if data_type == \"response.output_text.delta\":\n            print(data.delta, end=\"\", flush=True)\n</code></pre>"},{"location":"reference/sdk-compatibility/#sdk-event-types","title":"SDK Event Types","text":"Event Type Description Source <code>response.output_text.delta</code> Text output OpenAI Responses API <code>response.reasoning_summary_text.delta</code> Reasoning summary OpenAI Responses API <code>response.function_call_arguments.delta</code> Tool arguments OpenAI Responses API <code>response.output_item.added</code> New output item OpenAI Responses API <code>response.output_item.done</code> Output complete OpenAI Responses API <p>These are from the OpenAI Responses API, forwarded by the Agents SDK, and passed through by AF.</p> <p>AF adds its own events (<code>af.PhaseStarted</code>, <code>af.PhaseEnded</code>, <code>af.AgentResult</code>) but doesn't modify SDK events.</p>"},{"location":"reference/sdk-compatibility/#tool-and-handoff-support","title":"Tool and Handoff Support","text":"<p>Tools and handoffs work as SDK features:</p> <pre><code>def search_web(query: str) -&gt; str:\n    return f\"Results for: {query}\"\n\nagent = af.Agent(\n    name=\"researcher\",\n    instructions=\"Research topics using search.\",\n    model=\"gpt-5.2\",\n    tools=[search_web],  # Passed to SDK\n)\n</code></pre> <p>From Flow's perspective, tool calls and handoffs are internal to agent execution. AF doesn't expose or interpret them \u2014 they're SDK behavior.</p>"},{"location":"reference/sdk-compatibility/#output_type-support","title":"output_type Support","text":"<p>Structured output uses SDK's implementation:</p> <pre><code>from pydantic import BaseModel\n\nclass Analysis(BaseModel):\n    sentiment: str\n\n# Passed directly to SDK\nagent = af.Agent(\n    name=\"analyzer\",\n    instructions=\"Analyze sentiment.\",\n    output_type=Analysis,  # SDK handles this\n    model=\"gpt-5.2\",\n)\n</code></pre>"},{"location":"reference/sdk-compatibility/#version-compatibility","title":"Version Compatibility","text":"<p>AF is tested with:</p> <ul> <li><code>openai-agents</code> &gt;= 0.1.0</li> <li><code>openai-chatkit</code> &gt;= 0.1.0 (for ChatKit integration)</li> </ul> <p>For production, pin versions:</p> <pre><code>[project]\ndependencies = [\n    \"agentic-flow&gt;=0.35\",\n    \"openai-agents==0.1.0\",\n    \"openai-chatkit==0.1.0\",\n]\n</code></pre>"},{"location":"reference/sdk-compatibility/#execution-time-pass-through","title":"Execution-Time Pass-Through","text":"<p>In addition to Agent definition pass-through, AF supports execution-time parameters via modifiers:</p>"},{"location":"reference/sdk-compatibility/#runnerrun-parameters","title":"Runner.run() Parameters","text":"SDK Parameter AF Modifier Status <code>max_turns</code> <code>.max_turns(n)</code> Supported <code>run_config</code> <code>.run_config(cfg)</code> Supported <code>context</code> <code>.context(ctx)</code> Supported <code>previous_response_id</code> <code>.run_kwarg(...)</code> Pass-through <code>conversation_id</code> <code>.run_kwarg(...)</code> Pass-through <code>session</code> <code>af.Runner(session=...)</code> Injected"},{"location":"reference/sdk-compatibility/#runconfig-options","title":"RunConfig Options","text":"Option Description Axis <code>model</code> Override agent's model WHAT <code>model_settings</code> Override model settings WHAT <code>tracing_disabled</code> Disable tracing HOW <code>trace_include_sensitive_data</code> Include data in traces HOW <code>workflow_name</code> Name for tracing HOW <code>input_guardrails</code> Override input guardrails LIMITS <code>output_guardrails</code> Override output guardrails LIMITS <code>hooks</code> Run-level hooks WHEN"},{"location":"reference/sdk-compatibility/#example","title":"Example","text":"<pre><code>from agents import RunConfig\n\n# Combine multiple execution-time settings\nresult = await agent(\"complex task\") \\\n    .max_turns(10) \\\n    .context(app_context) \\\n    .run_config(RunConfig(\n        tracing_disabled=True,\n        workflow_name=\"my_workflow\",\n    )) \\\n    .stream()\n</code></pre>"},{"location":"reference/sdk-compatibility/#sdk-features-comparison","title":"SDK Features Comparison","text":"SDK Feature AF Support Notes Agent definition Full pass-through All Agent kwargs supported Runner.run() params Via modifiers <code>.max_turns()</code>, <code>.context()</code>, etc. Guardrails Pass-through Via af.Agent() or RunConfig AgentHooks Pass-through Via af.Agent(hooks=...) RunHooks Pass-through Via RunConfig Context (DI) Via <code>.context()</code> Tracing SDK default Disable via RunConfig MCP Pass-through Via tools parameter"},{"location":"reference/sdk-compatibility/#non-goals","title":"Non-Goals","text":"<p>Things AF intentionally does not do:</p> Non-Goal Reason Replace SDK Session Use SDK's implementation Custom output parsing SDK handles structured output Expose handoff details Handoffs are SDK-internal Modify StreamEvents Forward unchanged Provide default models Use SDK defaults Wrap guardrails Use SDK directly Wrap hooks Use SDK directly Custom tracing Use SDK tracing"},{"location":"reference/sdk-compatibility/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph AF[\"AF Layer\"]\n        A(Agent wrapper)\n        B(ExecutionSpec)\n        C(phase)\n        D(Runner)\n    end\n\n    subgraph SDK[\"OpenAI Agents SDK\"]\n        E(agents.Agent)\n        F(agents.Runner)\n        G(agents.Session)\n        H(agents.StreamEvent)\n    end\n\n    A --&gt; E\n    B --&gt; F\n    D --&gt; G\n    C --&gt; H</code></pre> <p>AF is a thin layer. The SDK does the heavy lifting.</p>"}]}